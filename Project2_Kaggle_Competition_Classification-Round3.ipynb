{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods, which will be used to get training and validation data loader.\n",
    "\n",
    "You need to write a custom dataset class to load data.\n",
    "\n",
    "**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "    ....\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "def get_data(args1, *args):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#global flag to indicate if the script is running in a local environment\n",
    "g_local_run: bool = True\n",
    "g_measure_mean_std = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchmetrics.classification import  MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from torchmetrics import MeanMetric\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class KenyanFood13Dataset(Dataset):\n",
    "\n",
    "    \"\"\"Custom Dataset for Kenyan Food 13 Classification Task\"\"\"\n",
    "    \"\"\" Accepts a CSV file with image ID and lable colums,\n",
    "    Will split total images into train and validation sets with 80:20 ratio\n",
    "    First 80% images will be used for training and remaining 20% for validation\n",
    "    Args:\n",
    "        annotations_file (string): Path to the csv file with annotations.\n",
    "        img_dir (string): Directory with all the images.\n",
    "        train (bool, optional): Indicates if the dataset is for training or validation.\n",
    "            Default is True for training set, False for validation set.\n",
    "        transform (callable, optional): Optional transform to be applied\n",
    "            on a sample.\n",
    "        target_transform (callable, optional): Optional transform to be applied\n",
    "    \"\"\"\n",
    "    def __init__(self, annotations_file, img_dir, train=True, transform=None, target_transform=None):\n",
    "\n",
    "        if g_local_run:\n",
    "            print(\"Running in local mode - loading data from local paths\")\n",
    "            #add 'local' to annotatins_file name\n",
    "            base, ext = os.path.splitext(annotations_file)\n",
    "            annotations_file = f\"{base}_local{ext}\"\n",
    "\n",
    "        # few error checks\n",
    "        if not os.path.exists(annotations_file):\n",
    "            raise FileNotFoundError(f\"Annotations file not found: {annotations_file}\")\n",
    "        if not os.path.exists(img_dir):\n",
    "            raise FileNotFoundError(f\"Image directory not found: {img_dir}\")\n",
    "\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.local_run = g_local_run\n",
    "\n",
    "        num_classes = len(self.img_labels['label'].unique())\n",
    "        self.num_classes = num_classes\n",
    "        print(f\"Dataset initialized with {len(self.img_labels)} samples belonging to {num_classes} classes.\")\n",
    "        #split into train and validation sets\n",
    "        split_index = int(0.8 * len(self.img_labels))\n",
    "        if train:\n",
    "            self.img_labels = self.img_labels.iloc[:split_index].reset_index(drop=True)\n",
    "            print(f\"Using {len(self.img_labels)} samples for training.\")\n",
    "        else:\n",
    "            self.img_labels = self.img_labels.iloc[split_index:].reset_index(drop=True)\n",
    "            print(f\"Using {len(self.img_labels)} samples for validation.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DataModule for Kenyan Food 13 Dataset\n",
    "class KenyanFood13DataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_config, mean=None, std=None):\n",
    "        super().__init__()\n",
    "        self.data_config = data_config\n",
    "        #split the data into train and validation sets based on annotations file contents\n",
    "        if g_local_run:\n",
    "            print(\"Running in local mode - loading data from local paths\")\n",
    "            #add 'local' to annotatins_file name\n",
    "            base, ext = os.path.splitext(self.data_config.annotations_file)\n",
    "            self.data_config.annotations_file = f\"{base}_local{ext}\"\n",
    "        if not os.path.exists(self.data_config.annotations_file):\n",
    "            raise FileNotFoundError(f\"Annotations file not found: {self.data_config.annotations_file}\")\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "\n",
    "        # Mean and Std for normalization - use provided values or defaults (ImageNet stats)\n",
    "        self.mean = mean if mean is not None else [0.485, 0.456, 0.406]\n",
    "        self.std = std if std is not None else [0.229, 0.224, 0.225]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Define transforms, will have common transforms for train and val, and augmentation for train only\n",
    "        #get height and width from data_config\n",
    "        if isinstance(self.data_config.input_size, int):\n",
    "            img_height = self.data_config.input_size\n",
    "            img_width = self.data_config.input_size\n",
    "        elif isinstance(self.data_config.input_size, tuple) and len(self.data_config.input_size) == 2:\n",
    "            img_height = self.data_config.input_size[0]\n",
    "            img_width = self.data_config.input_size[1]\n",
    "        else:\n",
    "            raise ValueError(\"input_size must be an int or a tuple of two ints (height, width)\")\n",
    "\n",
    "        common_transforms = transforms.Compose([\n",
    "            transforms.Resize((img_height, img_width)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self.mean, std=self.std)\n",
    "        ])\n",
    "        aug_transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop((img_height, img_width)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self.mean, std=self.std),\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "        ])\n",
    "        # Create datasets\n",
    "        self.train_dataset = KenyanFood13Dataset(\n",
    "            annotations_file=self.data_config.annotations_file,\n",
    "            img_dir=self.data_config.img_dir,\n",
    "            train=True,\n",
    "            transform=aug_transforms)\n",
    "        self.val_dataset = KenyanFood13Dataset(\n",
    "            annotations_file=self.data_config.annotations_file,\n",
    "            img_dir=self.data_config.img_dir,\n",
    "            train=False,\n",
    "            transform=common_transforms)\n",
    "        self.num_classes = self.train_dataset.num_classes\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.train_dataset is None:\n",
    "            raise RuntimeError(\"train_dataset is not initialized. Call setup() before requesting train_dataloader.\")\n",
    "        return DataLoader(self.train_dataset, batch_size=self.data_config.batch_size, shuffle=True, num_workers=self.data_config.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.val_dataset is None:\n",
    "            raise RuntimeError(\"val_dataset is not initialized. Call setup() before requesting val_dataloader.\")\n",
    "        return DataLoader(self.val_dataset, batch_size=self.data_config.batch_size, shuffle=False, num_workers=self.data_config.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "**Define your configuration here.**\n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"/kaggle/input/opencv-pytorch-project-2-classification-round-3\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# configurations\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 0.001\n",
    "    num_epochs: int = 10\n",
    "    momentum: float = 0.9\n",
    "    log_interval: int = 10\n",
    "    random_seed: int = 42\n",
    "\n",
    "    # Optimizer configuration\n",
    "    optimizer: str = \"sgd\"  # Options: 'sgd', 'adam', 'adamw'\n",
    "    weight_decay: float = 0.0001  # L2 regularization\n",
    "\n",
    "    # Learning rate scheduler configuration\n",
    "    use_scheduler: bool = True\n",
    "    scheduler: str = \"step\"  # Options: 'step', 'cosine', 'reduce_on_plateau'\n",
    "    lr_step_size: int = 5  # For StepLR: step size for learning rate decay\n",
    "    lr_gamma: float = 0.1  # For StepLR: multiplicative factor of learning rate decay\n",
    "\n",
    "    model_name: str = \"googlenet\" # base model we will use for transfer learning and fine-tuning\n",
    "    pretrained: bool = True # use pretrained weights for the base model\n",
    "    precision: str = \"float32\" # precision for training: float32, float16, bfloat16\n",
    "    fine_tune_start: int = 5 # layer from which to start fine-tuning (1 means all layers, higher means fewer layers)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfiguration:\n",
    "    annotations_file: str = \"../data/kenyan-food-13/train.csv\" if g_local_run else \"/kaggle/input/kenyan-food-13/train.csv\"\n",
    "    img_dir: str = \"../data/kenyan-food-13/images/images\" if g_local_run else \"/kaggle/input/kenyan-food-13/images/images\"\n",
    "    input_size: int = 224 # input image size for the model\n",
    "    num_workers: int = 4 # number of workers for data loading\n",
    "    batch_size: int = 32 # batch size for training and validation\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    output_dir: str = \"./output\" if g_local_run else \"/kaggle/working/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_config = DataConfiguration()\n",
    "train_config = TrainingConfiguration()\n",
    "system_config = SystemConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#we will have methods to calculate accuracy, f1-score, precision, recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LightningModule, we will use GoogleNet as base model for transfer learning and fine-tuning.\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class KenyanFood13Classifier(L.LightningModule):\n",
    "    def __init__(self, training_config: TrainingConfiguration, num_classes: int):\n",
    "        super(KenyanFood13Classifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Store training configuration\n",
    "        self.training_config = training_config\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Load base model\n",
    "        if training_config.model_name == \"googlenet\":\n",
    "            self.model = torchvision.models.googlenet(pretrained=training_config.pretrained)\n",
    "            # Replace the final layer\n",
    "            self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {training_config.model_name} not supported.\")\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.train_mean_loss = MeanMetric()\n",
    "        self.val_mean_loss = MeanMetric()\n",
    "\n",
    "        self.train_accuracy = MulticlassAccuracy(num_classes=num_classes, average='macro')\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=num_classes, average='macro')\n",
    "        self.train_f1 = MulticlassF1Score(num_classes=num_classes, average='macro')\n",
    "        self.val_f1 = MulticlassF1Score(num_classes=num_classes, average='macro')\n",
    "        self.train_precision = MulticlassPrecision(num_classes=num_classes, average='macro')\n",
    "        self.val_precision = MulticlassPrecision(num_classes=num_classes, average='macro')\n",
    "        self.train_recall = MulticlassRecall(num_classes=num_classes, average='macro')\n",
    "        self.val_recall = MulticlassRecall(num_classes=num_classes, average='macro')\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # get data from batch images, labels\n",
    "        images, labels = batch\n",
    "        # predictions\n",
    "        outputs = self(images)\n",
    "        # calculate loss, uses cross-entropy loss\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.train_mean_loss.update(loss)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        self.train_accuracy.update(preds, labels)\n",
    "        self.train_mean_loss.update(loss)\n",
    "        self.train_precision.update(preds, labels)\n",
    "        self.train_recall.update(preds, labels)\n",
    "        self.train_f1.update(preds, labels)\n",
    "        self.log('train/loss', self.train_mean_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train/acc', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        #update  epoch level metrics and reset\n",
    "        self.log('train/precision', self.train_precision.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('train/recall', self.train_recall.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('train/f1', self.train_f1.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('step', self.current_epoch, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return super().on_train_epoch_end()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # get data from batch images, labels\n",
    "        images, labels = batch\n",
    "        # predictions\n",
    "        outputs = self(images)\n",
    "        # calculate loss, uses cross-entropy loss\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.val_mean_loss.update(loss)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        self.val_accuracy.update(preds, labels)\n",
    "        self.val_precision.update(preds, labels)\n",
    "        self.val_recall.update(preds, labels)\n",
    "        self.val_f1.update(preds, labels)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('valid/loss', self.val_mean_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/acc', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/precision', self.val_precision, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('valid/recall', self.val_recall, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('valid/f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=False)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        #update  epoch level metrics and reset\n",
    "        self.log('valid/precision', self.val_precision.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/recall', self.val_recall.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/f1', self.val_f1.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('step', self.current_epoch, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return super().on_validation_epoch_end()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Create optimizer based on configuration\n",
    "        if self.training_config.optimizer.lower() == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                self.parameters(),\n",
    "                lr=self.training_config.learning_rate,\n",
    "                momentum=self.training_config.momentum,\n",
    "                weight_decay=self.training_config.weight_decay\n",
    "            )\n",
    "        elif self.training_config.optimizer.lower() == \"adam\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                self.parameters(),\n",
    "                lr=self.training_config.learning_rate,\n",
    "                weight_decay=self.training_config.weight_decay\n",
    "            )\n",
    "        elif self.training_config.optimizer.lower() == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(),\n",
    "                lr=self.training_config.learning_rate,\n",
    "                weight_decay=self.training_config.weight_decay\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer {self.training_config.optimizer} not supported.\")\n",
    "\n",
    "        # Configure learning rate scheduler if enabled\n",
    "        if self.training_config.use_scheduler:\n",
    "            if self.training_config.scheduler.lower() == \"step\":\n",
    "                scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                    optimizer,\n",
    "                    step_size=self.training_config.lr_step_size,\n",
    "                    gamma=self.training_config.lr_gamma\n",
    "                )\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"frequency\": 1\n",
    "                    }\n",
    "                }\n",
    "            elif self.training_config.scheduler.lower() == \"cosine\":\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer,\n",
    "                    T_max=self.training_config.num_epochs\n",
    "                )\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"frequency\": 1\n",
    "                    }\n",
    "                }\n",
    "            elif self.training_config.scheduler.lower() == \"reduce_on_plateau\":\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer,\n",
    "                    mode='max',\n",
    "                    factor=self.training_config.lr_gamma,\n",
    "                    patience=3\n",
    "                )\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"monitor\": \"valid/acc\",\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"frequency\": 1\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                raise ValueError(f\"Scheduler {self.training_config.scheduler} not supported.\")\n",
    "\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "\n",
    "**Write the methods or classes to be used for training and validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def training_validation(training_config: TrainingConfiguration,\n",
    "                        data_config: DataConfiguration,\n",
    "                        system_config: SystemConfiguration,\n",
    "                        model, data_module):\n",
    "\n",
    "    #random seed for reproducibility\n",
    "    L.seed_everything(training_config.random_seed)\n",
    "\n",
    "    if not model:\n",
    "        raise ValueError(\"Model must be provided for training. Please initialize the model before calling this function.\")\n",
    "    if not data_module:\n",
    "        raise ValueError(\" data module is required to run the model\")\n",
    "    model = model\n",
    "    data_module = data_module\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=system_config.output_dir,\n",
    "        filename=\"{epoch}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        monitor=\"valid/acc\",\n",
    "        mode=\"max\",\n",
    "        auto_insert_metric_name=False,\n",
    "        save_weights_only=True)\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"valid/acc\",\n",
    "        patience=3,\n",
    "        mode=\"max\")\n",
    "\n",
    "    # TensorBoard logger\n",
    "    tensorboard_logger = TensorBoardLogger(\n",
    "        save_dir=system_config.output_dir,\n",
    "        name=\"kenyan_food_logs\",\n",
    "        version=None,  # Auto-incrementing version\n",
    "        default_hp_metric=False\n",
    "    )\n",
    "\n",
    "    # Map precision string to PyTorch Lightning expected value\n",
    "    precision_map = {\n",
    "        \"float32\": 32,\n",
    "        \"float16\": 16,\n",
    "        \"bfloat16\": \"bf16\"\n",
    "    }\n",
    "    trainer_precision = precision_map.get(training_config.precision, 32)\n",
    "\n",
    "    # Map device to accelerator type\n",
    "    accelerator = \"gpu\" if system_config.device == \"cuda\" else \"cpu\"\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=training_config.num_epochs,\n",
    "        accelerator=accelerator,\n",
    "        devices=\"auto\",\n",
    "        precision=trainer_precision,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "        logger=tensorboard_logger,\n",
    "        default_root_dir=system_config.output_dir,\n",
    "        log_every_n_steps=training_config.log_interval\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    trainer.validate(model, datamodule=data_module)\n",
    "\n",
    "    return model, data_module, checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "**Define your model in this section.**\n",
    "\n",
    "**You are allowed to use any pre-trained model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "**Define those methods or classes, which have  not been covered in the above sections.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_dataset_mean_std(annotations_file, img_dir, img_size=(224, 224), sample_size=None):\n",
    "    \"\"\"\n",
    "    Calculate mean and std for the dataset.\n",
    "\n",
    "    Args:\n",
    "        annotations_file: Path to CSV with image filenames\n",
    "        img_dir: Directory containing images\n",
    "        img_size: Tuple of (height, width) to resize images to\n",
    "        sample_size: If provided, only use this many images for calculation (for speed)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mean, std) as lists of 3 values each for RGB channels\n",
    "    \"\"\"\n",
    "    if g_local_run:\n",
    "        base, ext = os.path.splitext(annotations_file)\n",
    "        annotations_file = f\"{base}_local{ext}\"\n",
    "\n",
    "    img_labels = pd.read_csv(annotations_file)\n",
    "\n",
    "    # Use subset for faster computation if specified\n",
    "    if sample_size and sample_size < len(img_labels):\n",
    "        img_labels = img_labels.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    print(f\"Calculating mean and std from {len(img_labels)} images...\")\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for idx, row in img_labels.iterrows():\n",
    "        img_path = os.path.join(img_dir, row.iloc[0])\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.resize(img_size)\n",
    "            img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "            # Calculate mean and std per channel\n",
    "            img_tensor = torch.tensor(img_array).permute(2, 0, 1)  # C, H, W\n",
    "            means.append(img_tensor.mean(dim=(1, 2)))\n",
    "            stds.append(img_tensor.std(dim=(1, 2)))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Calculate overall mean and std\n",
    "    mean = torch.stack(means).mean(dim=0).tolist()\n",
    "    std = torch.stack(stds).mean(dim=0).tolist()\n",
    "\n",
    "    print(f\"Calculated mean: {mean}\")\n",
    "    print(f\"Calculated std: {std}\")\n",
    "\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# mean, std = calculate_dataset_mean_std(\n",
    "#     annotations_file=data_config.annotations_file,\n",
    "#     img_dir=data_config.img_dir,\n",
    "#     img_size=(data_config.input_size, data_config.input_size),\n",
    "#     sample_size=1000  # Use subset for faster calculation, or None for all images\n",
    "# )\n",
    "\n",
    "# Then create DataModule with calculated values:\n",
    "# data_module = KenyanFood13DataModule(data_config, mean=mean, std=std)\n",
    "\n",
    "# Or use default ImageNet stats:\n",
    "# data_module = KenyanFood13DataModule(data_config)\n",
    "\n",
    "if g_measure_mean_std:\n",
    "    mean, std = calculate_dataset_mean_std(\n",
    "        annotations_file=data_config.annotations_file,\n",
    "        img_dir=data_config.img_dir,\n",
    "        img_size=(data_config.input_size, data_config.input_size),\n",
    "        sample_size=1000)  # Use subset for faster calculation, or None for all images\n",
    "    data_module = KenyanFood13DataModule(data_config=data_config, mean=mean, std=std)\n",
    "else:\n",
    "    data_module = KenyanFood13DataModule(data_config=data_config)\n",
    "\n",
    "# Setup data module to get num_classes\n",
    "data_module.setup()\n",
    "\n",
    "model = KenyanFood13Classifier(train_config, data_module.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Experiment [5 Points]</font>\n",
    "\n",
    "**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model, data_module, model_ckpt = training_validation(\n",
    "    training_config=train_config,\n",
    "    data_config=data_config,\n",
    "    system_config=system_config,\n",
    "    model=model,\n",
    "    data_module=data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Log Link [5 Points]</font>\n",
    "\n",
    "**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n",
    "\n",
    "\n",
    "Note: In light of the recent shutdown of tensorboard.dev, we have updated the submission requirements for your project. Instead of sharing a tensorboard.dev link, you are now required to upload your generated TensorBoard event files directly onto the lab. As an alternative, you may also include a screenshot of your TensorBoard output within your Jupyter notebook. This adjustment ensures that your data visualization and model training efforts are thoroughly documented and accessible for evaluation.\n",
    "\n",
    "You are also welcome (and encouraged) to utilize alternative logging services like wandB or comet. In such instances, you can easily make your project logs publicly accessible and share the link with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "**Share your Kaggle profile link  with us here to score , points in  the competition.**\n",
    "\n",
    "**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n",
    "\n",
    "\n",
    "**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10665762,
     "sourceId": 90936,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
