{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods, which will be used to get training and validation data loader.\n",
    "\n",
    "You need to write a custom dataset class to load data.\n",
    "\n",
    "**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "    ....\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "def get_data(args1, *args):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "#global flag to indicate if the script is running in a local environment\n",
    "g_local_run: bool = True\n",
    "g_measure_mean_std = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchmetrics.classification import  MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "from torchmetrics import MeanMetric\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "import traceback\n",
    "from dataclasses import dataclass\n",
    "from kenyan_data import KenyanFood13Dataset, KenyanFood13DataModule\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# class KenyanFood13Dataset(Dataset):\n",
    "#     \"\"\"Top-level dataset module for pickling across DataLoader workers.\n",
    "\n",
    "#     Notes:\n",
    "#     - Define this class in a standalone module (not in a notebook cell) so\n",
    "#       multiprocessing (spawn) on Windows can import it in worker processes.\n",
    "#     - The CSV is expected to contain at least two columns: an image id/filename\n",
    "#       and a class label. By default this implementation uses the first two\n",
    "#       columns, but it's safer to pass explicit column names (see args).\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  annotations_file: str,\n",
    "#                  img_dir: str,\n",
    "#                  train: bool = True,\n",
    "#                  transform: Optional[transforms.Compose] = None,\n",
    "#                  target_transform: Optional[callable] = None,\n",
    "#                  id_col: Optional[str] = None,\n",
    "#                  class_col: Optional[str] = None):\n",
    "\n",
    "#         annotations_file = os.path.abspath(annotations_file)\n",
    "#         img_dir = os.path.abspath(img_dir)\n",
    "\n",
    "#         if not os.path.exists(annotations_file):\n",
    "#             raise FileNotFoundError(f\"Annotations file not found: {annotations_file}\")\n",
    "#         if not os.path.exists(img_dir):\n",
    "#             raise FileNotFoundError(f\"Image directory not found: {img_dir}\")\n",
    "\n",
    "#         self.df = pd.read_csv(annotations_file)\n",
    "#         if self.df.shape[1] < 2:\n",
    "#             raise ValueError(\"Annotations CSV must contain at least two columns: id and class\")\n",
    "\n",
    "#         # determine columns\n",
    "#         if id_col is None:\n",
    "#             id_col = self.df.columns[0]\n",
    "#         if class_col is None:\n",
    "#             class_col = self.df.columns[1]\n",
    "\n",
    "#         self.id_col = id_col\n",
    "#         self.class_col = class_col\n",
    "\n",
    "#         # ensure strings for ids and classes\n",
    "#         self.df[self.id_col] = self.df[self.id_col].astype(str)\n",
    "#         self.df[self.class_col] = self.df[self.class_col].astype(str)\n",
    "\n",
    "#         # build label mapping using the full CSV so mapping is consistent\n",
    "#         unique_labels = self.df[self.class_col].unique()\n",
    "#         self.label2idx = {label: int(idx) for idx, label in enumerate(sorted(unique_labels))}\n",
    "#         self.idx2label = {int(idx): label for label, idx in self.label2idx.items()}\n",
    "\n",
    "#         self.img_dir = img_dir\n",
    "#         self.transform = transform\n",
    "#         self.target_transform = target_transform\n",
    "#         self.train = train\n",
    "\n",
    "#         # split dataset (80:20)\n",
    "#         total = len(self.df)\n",
    "#         split_index = int(0.8 * total)\n",
    "#         if self.train:\n",
    "#             self.df = self.df.iloc[:split_index].reset_index(drop=True)\n",
    "#         else:\n",
    "#             self.df = self.df.iloc[split_index:].reset_index(drop=True)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if torch.is_tensor(idx):\n",
    "#             idx = idx.tolist()\n",
    "\n",
    "#         row = self.df.iloc[idx]\n",
    "#         img_id = str(row[self.id_col])\n",
    "#         img_path = os.path.join(self.img_dir, img_id if img_id.lower().endswith(('.jpg', '.jpeg', '.png')) else img_id + '.jpg')\n",
    "\n",
    "#         try:\n",
    "#             image = Image.open(img_path).convert('RGB')\n",
    "#         except Exception as e:\n",
    "#             raise RuntimeError(f\"Failed to open image {img_path}: {e}\")\n",
    "\n",
    "#         label_str = str(row[self.class_col])\n",
    "#         label = self.label2idx.get(label_str)\n",
    "#         if label is None:\n",
    "#             raise KeyError(f\"Label '{label_str}' not found in label2idx mapping\")\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         if self.target_transform:\n",
    "#             label = self.target_transform(label)\n",
    "\n",
    "#         return image, int(label)\n",
    "\n",
    "\n",
    "# # DataModule for Kenyan Food 13 Dataset\n",
    "# class KenyanFood13DataModule(L.LightningDataModule):\n",
    "#     def __init__(self, data_config, mean=None, std=None):\n",
    "#         super().__init__()\n",
    "#         self.data_config = data_config\n",
    "#         self.train_dataset = None\n",
    "#         self.val_dataset = None\n",
    "\n",
    "#         # Mean and Std for normalization - use provided values or defaults (ImageNet stats)\n",
    "#         self.mean = mean if mean is not None else [0.485, 0.456, 0.406]\n",
    "#         self.std = std if std is not None else [0.229, 0.224, 0.225]\n",
    "\n",
    "#     def setup(self, stage=None):\n",
    "#         # Define transforms, will have common transforms for train and val, and augmentation for train only\n",
    "#         #get height and width from data_config\n",
    "#         if isinstance(self.data_config.input_size, int):\n",
    "#             img_height = self.data_config.input_size\n",
    "#             img_width = self.data_config.input_size\n",
    "#         elif isinstance(self.data_config.input_size, tuple) and len(self.data_config.input_size) == 2:\n",
    "#             img_height = self.data_config.input_size[0]\n",
    "#             img_width = self.data_config.input_size[1]\n",
    "#         else:\n",
    "#             raise ValueError(\"input_size must be an int or a tuple of two ints (height, width)\")\n",
    "\n",
    "#         common_transforms = transforms.Compose([\n",
    "#             transforms.Resize((img_height, img_width)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=self.mean, std=self.std)\n",
    "#         ])\n",
    "#         aug_transforms = transforms.Compose([\n",
    "#             transforms.RandomResizedCrop((img_height, img_width)),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "#             transforms.RandomVerticalFlip(),\n",
    "#             transforms.RandomRotation(15),\n",
    "#             transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=self.mean, std=self.std),\n",
    "#             transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "#         ])\n",
    "#         # Create datasets\n",
    "#         self.train_dataset = KenyanFood13Dataset(\n",
    "#             annotations_file=self.data_config.annotations_file,\n",
    "#             img_dir=self.data_config.img_dir,\n",
    "#             train=True,\n",
    "#             transform=aug_transforms)\n",
    "#         self.val_dataset = KenyanFood13Dataset(\n",
    "#             annotations_file=self.data_config.annotations_file,\n",
    "#             img_dir=self.data_config.img_dir,\n",
    "#             train=False,\n",
    "#             transform=common_transforms)\n",
    "#         self.num_classes = self.train_dataset.num_classes\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         if self.train_dataset is None:\n",
    "#             raise RuntimeError(\"train_dataset is not initialized. Call setup() before requesting train_dataloader.\")\n",
    "#         return DataLoader(self.train_dataset, batch_size=self.data_config.batch_size, shuffle=True, num_workers=self.data_config.num_workers)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         if self.val_dataset is None:\n",
    "#             raise RuntimeError(\"val_dataset is not initialized. Call setup() before requesting val_dataloader.\")\n",
    "#         return DataLoader(self.val_dataset, batch_size=self.data_config.batch_size,\n",
    "#                           shuffle=False, num_workers=self.data_config.num_workers,\n",
    "#                           persistent_workers=True if self.data_config.num_workers > 0 else False)\n",
    "\n",
    "\n",
    "# class KenyanFood13DataModule:\n",
    "#     \"\"\"Lightweight DataModule-like helper that returns DataLoaders.\n",
    "\n",
    "#     This is intentionally minimal so you can import the classes and then create\n",
    "#     DataLoaders with desired num_workers on Windows/macOS/Linux.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, data_config, mean=None, std=None):\n",
    "#         self.data_config = data_config\n",
    "#         self.mean = mean if mean is not None else [0.485, 0.456, 0.406]\n",
    "#         self.std = std if std is not None else [0.229, 0.224, 0.225]\n",
    "#         self.train_dataset = None\n",
    "#         self.val_dataset = None\n",
    "\n",
    "#     def setup(self):\n",
    "#         if isinstance(self.data_config.input_size, int):\n",
    "#             h = w = self.data_config.input_size\n",
    "#         else:\n",
    "#             h, w = self.data_config.input_size\n",
    "\n",
    "#         common_transforms = transforms.Compose([\n",
    "#             transforms.Resize((h, w)),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=self.mean, std=self.std),\n",
    "#         ])\n",
    "\n",
    "#         aug_transforms = transforms.Compose([\n",
    "#             transforms.RandomResizedCrop((h, w)),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "#             transforms.RandomRotation(15),\n",
    "#             transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "#             transforms.ToTensor(),\n",
    "#             transforms.Normalize(mean=self.mean, std=self.std),\n",
    "#         ])\n",
    "\n",
    "#         self.train_dataset = KenyanFood13Dataset(\n",
    "#             annotations_file=self.data_config.annotations_file,\n",
    "#             img_dir=self.data_config.img_dir,\n",
    "#             train=True,\n",
    "#             transform=aug_transforms\n",
    "#         )\n",
    "\n",
    "#         self.val_dataset = KenyanFood13Dataset(\n",
    "#             annotations_file=self.data_config.annotations_file,\n",
    "#             img_dir=self.data_config.img_dir,\n",
    "#             train=False,\n",
    "#             transform=common_transforms\n",
    "#         )\n",
    "\n",
    "#         self.num_classes = len(self.train_dataset.label2idx)\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         if self.train_dataset is None:\n",
    "#             raise RuntimeError('Call setup() before train_dataloader()')\n",
    "#         return DataLoader(self.train_dataset,\n",
    "#                           batch_size=self.data_config.batch_size,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=self.data_config.num_workers,\n",
    "#                           pin_memory=True if torch.cuda.is_available() else False)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         if self.val_dataset is None:\n",
    "#             raise RuntimeError('Call setup() before val_dataloader()')\n",
    "#         return DataLoader(self.val_dataset,\n",
    "#                           batch_size=self.data_config.batch_size,\n",
    "#                           shuffle=False,\n",
    "#                           num_workers=self.data_config.num_workers,\n",
    "#                           pin_memory=True if torch.cuda.is_available() else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataloader_test.py\n",
    "# # from kenyan_data import KenyanFood13DataModule\n",
    "\n",
    "# # Minimal DataConfiguration compatible with your DataConfiguration dataclass in the notebook.\n",
    "# @dataclass\n",
    "# class DummyDataConfig:\n",
    "#     annotations_file: str = \"../../data/kenyan-food-13/train_local.csv\"\n",
    "#     img_dir: str = \"../../data/kenyan-food-13/images/images\"\n",
    "#     input_size: int = 224\n",
    "#     num_workers: int = 4\n",
    "#     batch_size: int = 32\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     def inspect_loader(loader, name=\"loader\"):\n",
    "#         it = iter(loader)\n",
    "#         batch = next(it)\n",
    "#         images, labels = batch\n",
    "#         print(f\"{name} - images.shape: {images.shape}, labels.shape: {labels.shape}\")\n",
    "#         try:\n",
    "#             unique, counts = torch.unique(labels, return_counts=True)\n",
    "#             print(f\"{name} - label counts in batch: {dict(zip(unique.tolist(), counts.tolist()))}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Could not compute label counts: {e}\")\n",
    "\n",
    "#     cfg = DummyDataConfig()\n",
    "#     dm = KenyanFood13DataModule(data_config=cfg)\n",
    "#     ds = dm.train_dataset\n",
    "#     print(\"dataset class module:\", ds.__class__.__module__)\n",
    "#     print(\"dataset class qualname:\", ds.__class__.__qualname__)\n",
    "#     try:\n",
    "#         dm.setup()\n",
    "#         tr_dl = dm.train_dataloader()\n",
    "#         vl_dl = dm.val_dataloader()\n",
    "#         inspect_loader(tr_dl, 'train')\n",
    "#         inspect_loader(vl_dl, 'val')\n",
    "\n",
    "#     except Exception:\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# TEST: DataLoader with num_workers from notebook-defined class\n",
    "# This test will FAIL with num_workers > 0 because notebook classes aren't picklable\n",
    "\n",
    "# from kenyan_data import KenyanFood13DataModule\n",
    "\n",
    "# @dataclass\n",
    "# class DummyDataConfig:\n",
    "#     annotations_file: str = \"../../data/kenyan-food-13/train_local.csv\"\n",
    "#     img_dir: str = \"../../data/kenyan-food-13/images/images\"\n",
    "#     input_size: int = 224\n",
    "#     num_workers: int = 4  # IMPORTANT: Keep 0 for notebook classes, use >0 only with kenyan_data.py import\n",
    "#     batch_size: int = 32\n",
    "\n",
    "# def inspect_loader(loader, name=\"loader\"):\n",
    "#     it = iter(loader)\n",
    "#     batch = next(it)\n",
    "#     images, labels = batch\n",
    "#     print(f\"{name} - images.shape: {images.shape}, labels.shape: {labels.shape}\")\n",
    "#     try:\n",
    "#         unique, counts = torch.unique(labels, return_counts=True)\n",
    "#         print(f\"{name} - label counts in batch: {dict(zip(unique.tolist(), counts.tolist()))}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not compute label counts: {e}\")\n",
    "\n",
    "# cfg = DummyDataConfig()\n",
    "# dm = KenyanFood13DataModule(data_config=cfg)\n",
    "# try:\n",
    "#     dm.setup()\n",
    "#     print(\"\\nðŸ“Œ IMPORTANT:\")\n",
    "#     print(\"  - Dataset defined in notebook: __module__ =\", dm.train_dataset.__class__.__module__)\n",
    "#     print(\"  - With num_workers > 0, multiprocessing WILL FAIL (can't pickle notebook classes)\")\n",
    "#     print(\"  - To use num_workers > 0, use: from kenyan_data import KenyanFood13Dataset\")\n",
    "#     print(\"\\nâœ“ Testing with num_workers=0:\")\n",
    "#     tr_dl = dm.train_dataloader()\n",
    "#     vl_dl = dm.val_dataloader()\n",
    "#     inspect_loader(tr_dl, 'train')\n",
    "#     inspect_loader(vl_dl, 'val')\n",
    "#     print(\"\\nâœ“ SUCCESS with num_workers=0\")\n",
    "# except Exception as e:\n",
    "#     print(\"\\nâœ— FAILED:\")\n",
    "#     traceback.print_exc()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "**Define your configuration here.**\n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"/kaggle/input/opencv-pytorch-project-2-classification-round-3\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in local mode - loading data from local paths\n"
     ]
    }
   ],
   "source": [
    "# configurations\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 0.001\n",
    "    num_epochs: int = 10\n",
    "    momentum: float = 0.9\n",
    "    log_interval: int = 5\n",
    "    random_seed: int = 42\n",
    "\n",
    "    # Optimizer configuration\n",
    "    optimizer: str = \"sgd\"  # Options: 'sgd', 'adam', 'adamw'\n",
    "    weight_decay: float = 0.0001  # L2 regularization\n",
    "\n",
    "    # Learning rate scheduler configuration\n",
    "    use_scheduler: bool = True\n",
    "    scheduler: str = \"step\"  # Options: 'step', 'cosine', 'reduce_on_plateau'\n",
    "    lr_step_size: int = 5  # For StepLR: step size for learning rate decay\n",
    "    lr_gamma: float = 0.1  # For StepLR: multiplicative factor of learning rate decay\n",
    "\n",
    "    model_name: str = \"googlenet\" # base model we will use for transfer learning and fine-tuning\n",
    "    pretrained: bool = True # use pretrained weights for the base model\n",
    "    precision: str = \"float32\" # precision for training: float32, float16, bfloat16\n",
    "    fine_tune_start: int = 5 # layer from which to start fine-tuning (1 means all layers, higher means fewer layers)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfiguration:\n",
    "    if g_local_run:\n",
    "        print(\"Running in local mode - loading data from local paths\")\n",
    "    annotations_file: str = \"../../data/kenyan-food-13/train_local.csv\" if g_local_run else \"/kaggle/input/kenyan-food-13/train.csv\"\n",
    "    img_dir: str = \"../../data/kenyan-food-13/images/images\" if g_local_run else \"/kaggle/input/kenyan-food-13/images/images\"\n",
    "    #check if annotations file and data exist\n",
    "    try:\n",
    "        annotations_file = os.path.abspath(annotations_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error resolving path for annotations_file: {e}\")\n",
    "        exit(1)\n",
    "    try:\n",
    "        img_dir = os.path.abspath(img_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Error resolving path for img_dir: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "\n",
    "    input_size: int = 224 # input image size for the model\n",
    "    num_workers: int = 4 # number of workers for data loading\n",
    "    batch_size: int = 32 # batch size for training and validation\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    output_dir: str = \"./output\" if g_local_run else \"/kaggle/working/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_config = DataConfiguration()\n",
    "train_config = TrainingConfiguration()\n",
    "system_config = SystemConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#we will have methods to calculate accuracy, f1-score, precision, recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LightningModule, we will use GoogleNet as base model for transfer learning and fine-tuning.\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class KenyanFood13Classifier(L.LightningModule):\n",
    "    def __init__(self, training_config: TrainingConfiguration, num_classes: int):\n",
    "        super(KenyanFood13Classifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Store training configuration\n",
    "        self.training_config = training_config\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Load base model\n",
    "        if training_config.model_name == \"googlenet\":\n",
    "            if train_config.pretrained:\n",
    "                weights = torchvision.models.GoogLeNet_Weights.IMAGENET1K_V1\n",
    "            else:\n",
    "                weights = None\n",
    "            self.model = torchvision.models.googlenet(weights=weights)\n",
    "            # Replace the final layer\n",
    "            self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {training_config.model_name} not supported.\")\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.train_mean_loss = MeanMetric()\n",
    "        self.val_mean_loss = MeanMetric()\n",
    "\n",
    "        self.train_accuracy = MulticlassAccuracy(num_classes=num_classes, average='macro')\n",
    "        self.val_accuracy = MulticlassAccuracy(num_classes=num_classes, average='macro')\n",
    "        self.train_f1 = MulticlassF1Score(num_classes=num_classes, average='macro')\n",
    "        self.val_f1 = MulticlassF1Score(num_classes=num_classes, average='macro')\n",
    "        self.train_precision = MulticlassPrecision(num_classes=num_classes, average='macro')\n",
    "        self.val_precision = MulticlassPrecision(num_classes=num_classes, average='macro')\n",
    "        self.train_recall = MulticlassRecall(num_classes=num_classes, average='macro')\n",
    "        self.val_recall = MulticlassRecall(num_classes=num_classes, average='macro')\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # get data from batch images, labels\n",
    "        images, labels = batch\n",
    "        # predictions\n",
    "        outputs = self(images)\n",
    "        # calculate loss, uses cross-entropy loss\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.train_mean_loss.update(loss)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        self.train_accuracy.update(preds, labels)\n",
    "        self.train_mean_loss.update(loss)\n",
    "        self.train_precision.update(preds, labels)\n",
    "        self.train_recall.update(preds, labels)\n",
    "        self.train_f1.update(preds, labels)\n",
    "        self.log('train/loss', self.train_mean_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train/acc', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        #update  epoch level metrics and reset\n",
    "        self.log('train/precision', self.train_precision.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('train/recall', self.train_recall.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('train/f1', self.train_f1.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('step', self.current_epoch, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return super().on_train_epoch_end()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # get data from batch images, labels\n",
    "        images, labels = batch\n",
    "        # predictions\n",
    "        outputs = self(images)\n",
    "        # calculate loss, uses cross-entropy loss\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.val_mean_loss.update(loss)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        self.val_accuracy.update(preds, labels)\n",
    "        self.val_precision.update(preds, labels)\n",
    "        self.val_recall.update(preds, labels)\n",
    "        self.val_f1.update(preds, labels)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('valid/loss', self.val_mean_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/acc', self.val_accuracy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/precision', self.val_precision, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('valid/recall', self.val_recall, on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('valid/f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=False)\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        #update  epoch level metrics and reset\n",
    "        self.log('valid/precision', self.val_precision.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/recall', self.val_recall.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('valid/f1', self.val_f1.compute(), on_epoch=True, prog_bar=True)\n",
    "        self.log('step', self.current_epoch, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return super().on_validation_epoch_end()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Create optimizer based on configuration\n",
    "        if self.training_config.optimizer.lower() == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                self.parameters(),\n",
    "                lr=self.training_config.learning_rate,\n",
    "                momentum=self.training_config.momentum,\n",
    "                weight_decay=self.training_config.weight_decay\n",
    "            )\n",
    "        elif self.training_config.optimizer.lower() == \"adam\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                self.parameters(),\n",
    "                lr=self.training_config.learning_rate,\n",
    "                weight_decay=self.training_config.weight_decay\n",
    "            )\n",
    "        elif self.training_config.optimizer.lower() == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(),\n",
    "                lr=self.training_config.learning_rate,\n",
    "                weight_decay=self.training_config.weight_decay\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer {self.training_config.optimizer} not supported.\")\n",
    "\n",
    "        # Configure learning rate scheduler if enabled\n",
    "        if self.training_config.use_scheduler:\n",
    "            if self.training_config.scheduler.lower() == \"step\":\n",
    "                scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                    optimizer,\n",
    "                    step_size=self.training_config.lr_step_size,\n",
    "                    gamma=self.training_config.lr_gamma\n",
    "                )\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"frequency\": 1\n",
    "                    }\n",
    "                }\n",
    "            elif self.training_config.scheduler.lower() == \"cosine\":\n",
    "                scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                    optimizer,\n",
    "                    T_max=self.training_config.num_epochs\n",
    "                )\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"frequency\": 1\n",
    "                    }\n",
    "                }\n",
    "            elif self.training_config.scheduler.lower() == \"reduce_on_plateau\":\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer,\n",
    "                    mode='max',\n",
    "                    factor=self.training_config.lr_gamma,\n",
    "                    patience=3\n",
    "                )\n",
    "                return {\n",
    "                    \"optimizer\": optimizer,\n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"monitor\": \"valid/acc\",\n",
    "                        \"interval\": \"epoch\",\n",
    "                        \"frequency\": 1\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                raise ValueError(f\"Scheduler {self.training_config.scheduler} not supported.\")\n",
    "\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "\n",
    "**Write the methods or classes to be used for training and validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def training_validation(training_config: TrainingConfiguration,\n",
    "                        data_config: DataConfiguration,\n",
    "                        system_config: SystemConfiguration,\n",
    "                        model, data_module):\n",
    "\n",
    "    #random seed for reproducibility\n",
    "    L.seed_everything(training_config.random_seed)\n",
    "\n",
    "    if not model:\n",
    "        raise ValueError(\"Model must be provided for training. Please initialize the model before calling this function.\")\n",
    "    if not data_module:\n",
    "        raise ValueError(\" data module is required to run the model\")\n",
    "    model = model\n",
    "    data_module = data_module\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=system_config.output_dir,\n",
    "        filename=\"{epoch}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        monitor=\"valid/acc\",\n",
    "        mode=\"max\",\n",
    "        auto_insert_metric_name=False,\n",
    "        save_weights_only=True)\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"valid/acc\",\n",
    "        patience=3,\n",
    "        mode=\"max\")\n",
    "\n",
    "    # TensorBoard logger\n",
    "    tensorboard_logger = TensorBoardLogger(\n",
    "        save_dir=system_config.output_dir,\n",
    "        name=\"kenyan_food_logs\",\n",
    "        version=None,  # Auto-incrementing version\n",
    "        default_hp_metric=False\n",
    "    )\n",
    "\n",
    "    # Map precision string to PyTorch Lightning expected value\n",
    "    precision_map = {\n",
    "        \"float32\": 32,\n",
    "        \"float16\": 16,\n",
    "        \"bfloat16\": \"bf16\"\n",
    "    }\n",
    "    trainer_precision = precision_map.get(training_config.precision, 32)\n",
    "\n",
    "    # Map device to accelerator type\n",
    "    accelerator = \"gpu\" if system_config.device == \"cuda\" else \"cpu\"\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=training_config.num_epochs,\n",
    "        accelerator=accelerator,\n",
    "        devices=\"auto\",\n",
    "        precision=trainer_precision,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "        logger=tensorboard_logger,\n",
    "        default_root_dir=system_config.output_dir,\n",
    "        log_every_n_steps=training_config.log_interval\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "    trainer.validate(model, datamodule=data_module)\n",
    "\n",
    "    return model, data_module, checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "**Define your model in this section.**\n",
    "\n",
    "**You are allowed to use any pre-trained model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "**Define those methods or classes, which have  not been covered in the above sections.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_dataset_mean_std(annotations_file, img_dir, img_size=(224, 224), sample_size=None):\n",
    "    \"\"\"\n",
    "    Calculate mean and std for the dataset.\n",
    "\n",
    "    Args:\n",
    "        annotations_file: Path to CSV with image filenames\n",
    "        img_dir: Directory containing images\n",
    "        img_size: Tuple of (height, width) to resize images to\n",
    "        sample_size: If provided, only use this many images for calculation (for speed)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (mean, std) as lists of 3 values each for RGB channels\n",
    "    \"\"\"\n",
    "    # if g_local_run:\n",
    "    #     base, ext = os.path.splitext(annotations_file)\n",
    "    #     annotations_file = f\"{base}_local{ext}\"\n",
    "\n",
    "    img_labels = pd.read_csv(annotations_file)\n",
    "\n",
    "    # Use subset for faster computation if specified\n",
    "    if sample_size and sample_size < len(img_labels):\n",
    "        img_labels = img_labels.sample(n=sample_size, random_state=42)\n",
    "\n",
    "    print(f\"Calculating mean and std from {len(img_labels)} images...\")\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "\n",
    "    for idx, row in img_labels.iterrows():\n",
    "        img_path = os.path.join(img_dir, str(row.iloc[0])+'.jpg')\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = img.resize(img_size)\n",
    "            img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "            # Calculate mean and std per channel\n",
    "            img_tensor = torch.tensor(img_array).permute(2, 0, 1)  # C, H, W\n",
    "            means.append(img_tensor.mean(dim=(1, 2)))\n",
    "            stds.append(img_tensor.std(dim=(1, 2)))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Calculate overall mean and std\n",
    "    mean = torch.stack(means).mean(dim=0).tolist()\n",
    "    std = torch.stack(stds).mean(dim=0).tolist()\n",
    "\n",
    "    print(f\"Calculated mean: {mean}\")\n",
    "    print(f\"Calculated std: {std}\")\n",
    "\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean and std from 30 images...\n",
      "Calculated mean: [0.6001899353491397, 0.5017203443877551, 0.39458859064459123]\n",
      "Calculated std: [0.24288309692516058, 0.2552360359103688, 0.2709235466590576]\n",
      "Calculated mean: [0.6001899353491397, 0.5017203443877551, 0.39458859064459123]\n",
      "Calculated std: [0.24288309692516058, 0.2552360359103688, 0.2709235466590576]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mean, std = calculate_dataset_mean_std(\n",
    "#     annotations_file=data_config.annotations_file,\n",
    "#     img_dir=data_config.img_dir,\n",
    "#     img_size=(data_config.input_size, data_config.input_size),\n",
    "#     sample_size=1000  # Use subset for faster calculation, or None for all images\n",
    "# )\n",
    "\n",
    "# Then create DataModule with calculated values:\n",
    "# data_module = KenyanFood13DataModule(data_config, mean=mean, std=std)\n",
    "\n",
    "# Or use default ImageNet stats:\n",
    "# data_module = KenyanFood13DataModule(data_config)\n",
    "\n",
    "if g_measure_mean_std:\n",
    "    mean, std = calculate_dataset_mean_std(\n",
    "        annotations_file=data_config.annotations_file,\n",
    "        img_dir=data_config.img_dir,\n",
    "        img_size=(data_config.input_size, data_config.input_size),\n",
    "        sample_size=30)  # Use subset for faster calculation, or None for all images\n",
    "    # mean = [0.485, 0.456, 0.406]\n",
    "    # std = [0.229, 0.224, 0.225]\n",
    "    data_module = KenyanFood13DataModule(data_config=data_config, mean=mean, std=std)\n",
    "else:\n",
    "    data_module = KenyanFood13DataModule(data_config=data_config)\n",
    "\n",
    "# Setup data module to get num_classes\n",
    "data_module.setup()\n",
    "\n",
    "model = KenyanFood13Classifier(train_config, data_module.num_classes)\n",
    "\n",
    "# ds = data_module.train_dataset\n",
    "# print(\"dataset class module:\", ds.__class__.__module__)\n",
    "# print(\"dataset class qualname:\", ds.__class__.__qualname__)\n",
    "\n",
    "\n",
    "# # Verification cell inserted by assistant: check dataloaders and one sample batch\n",
    "# # This cell calls data_module.train_dataloader() and data_module.val_dataloader(),\n",
    "# # fetches one batch and prints tensor shapes and label distributions.\n",
    "# try:\n",
    "#     print(\"Verifying dataloaders...\")\n",
    "#     train_loader = data_module.train_dataloader()\n",
    "#     val_loader = data_module.val_dataloader()\n",
    "#     print(f\"Train loader: {train_loader}\")\n",
    "#     print(f\"Val loader: {val_loader}\")\n",
    "\n",
    "#     def inspect_loader(loader, name=\"loader\"):\n",
    "#         it = iter(loader)\n",
    "#         batch = next(it)\n",
    "#         images, labels = batch\n",
    "#         print(f\"{name} - images.shape: {images.shape}, labels.shape: {labels.shape}\")\n",
    "#         try:\n",
    "#             unique, counts = torch.unique(labels, return_counts=True)\n",
    "#             print(f\"{name} - label counts in batch: {dict(zip(unique.tolist(), counts.tolist()))}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Could not compute label counts: {e}\")\n",
    "\n",
    "#     inspect_loader(train_loader, 'train')\n",
    "#     inspect_loader(val_loader, 'val')\n",
    "# except Exception as e:\n",
    "#     print(\"Error while verifying dataloaders:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# t = data_module.train_dataset.transform\n",
    "# try:\n",
    "#     pickle.dumps(t)\n",
    "#     print(\"transform pickles OK\")\n",
    "# except Exception as e:\n",
    "#     print(\"transform pickling failed:\", type(e), e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "c:\\rama\\opencv\\projects\\.venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:881: Checkpoint directory C:\\rama\\opencv\\projects\\prj-2-opencv-dl-pytorch\\output exists and is not empty.\n",
      "\n",
      "   | Name            | Type                | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------------------------\n",
      "0  | model           | GoogLeNet           | 5.6 M  | train | 0    \n",
      "1  | criterion       | CrossEntropyLoss    | 0      | train | 0    \n",
      "2  | train_mean_loss | MeanMetric          | 0      | train | 0    \n",
      "3  | val_mean_loss   | MeanMetric          | 0      | train | 0    \n",
      "4  | train_accuracy  | MulticlassAccuracy  | 0      | train | 0    \n",
      "5  | val_accuracy    | MulticlassAccuracy  | 0      | train | 0    \n",
      "6  | train_f1        | MulticlassF1Score   | 0      | train | 0    \n",
      "7  | val_f1          | MulticlassF1Score   | 0      | train | 0    \n",
      "8  | train_precision | MulticlassPrecision | 0      | train | 0    \n",
      "9  | val_precision   | MulticlassPrecision | 0      | train | 0    \n",
      "10 | train_recall    | MulticlassRecall    | 0      | train | 0    \n",
      "11 | val_recall      | MulticlassRecall    | 0      | train | 0    \n",
      "-------------------------------------------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.449    Total estimated model params size (MB)\n",
      "235       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n",
      "c:\\rama\\opencv\\projects\\.venv\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:881: Checkpoint directory C:\\rama\\opencv\\projects\\prj-2-opencv-dl-pytorch\\output exists and is not empty.\n",
      "\n",
      "   | Name            | Type                | Params | Mode  | FLOPs\n",
      "-------------------------------------------------------------------------\n",
      "0  | model           | GoogLeNet           | 5.6 M  | train | 0    \n",
      "1  | criterion       | CrossEntropyLoss    | 0      | train | 0    \n",
      "2  | train_mean_loss | MeanMetric          | 0      | train | 0    \n",
      "3  | val_mean_loss   | MeanMetric          | 0      | train | 0    \n",
      "4  | train_accuracy  | MulticlassAccuracy  | 0      | train | 0    \n",
      "5  | val_accuracy    | MulticlassAccuracy  | 0      | train | 0    \n",
      "6  | train_f1        | MulticlassF1Score   | 0      | train | 0    \n",
      "7  | val_f1          | MulticlassF1Score   | 0      | train | 0    \n",
      "8  | train_precision | MulticlassPrecision | 0      | train | 0    \n",
      "9  | val_precision   | MulticlassPrecision | 0      | train | 0    \n",
      "10 | train_recall    | MulticlassRecall    | 0      | train | 0    \n",
      "11 | val_recall      | MulticlassRecall    | 0      | train | 0    \n",
      "-------------------------------------------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.449    Total estimated model params size (MB)\n",
      "235       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\rama\\opencv\\projects\\.venv\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:317: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  0.21it/s, v_num=8, valid/loss=2.590, valid/acc=0.0625, valid/precision=0.0156, valid/recall=0.0625, valid/f1=0.025, step=6.000, train/loss_epoch=2.310, train/acc_epoch=0.175, train/precision=0.126, train/recall=0.125, train/f1=0.0951]  \n",
      "\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.48it/s]\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "     Validate metric           DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "          step                      7.0\n",
      "        valid/acc                 0.0625\n",
      "        valid/f1            0.02500000037252903\n",
      "       valid/loss           2.5868210792541504\n",
      "     valid/precision             0.015625\n",
      "      valid/recall                0.0625\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "     Validate metric           DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "          step                      7.0\n",
      "        valid/acc                 0.0625\n",
      "        valid/f1            0.02500000037252903\n",
      "       valid/loss           2.5868210792541504\n",
      "     valid/precision             0.015625\n",
      "      valid/recall                0.0625\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    }
   ],
   "source": [
    "_, data_module, model_ckpt = training_validation(\n",
    "    training_config=train_config,\n",
    "    data_config=data_config,\n",
    "    system_config=system_config,\n",
    "    model=model,\n",
    "    data_module=data_module\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Log Link [5 Points]</font>\n",
    "\n",
    "**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n",
    "\n",
    "\n",
    "Note: In light of the recent shutdown of tensorboard.dev, we have updated the submission requirements for your project. Instead of sharing a tensorboard.dev link, you are now required to upload your generated TensorBoard event files directly onto the lab. As an alternative, you may also include a screenshot of your TensorBoard output within your Jupyter notebook. This adjustment ensures that your data visualization and model training efforts are thoroughly documented and accessible for evaluation.\n",
    "\n",
    "You are also welcome (and encouraged) to utilize alternative logging services like wandB or comet. In such instances, you can easily make your project logs publicly accessible and share the link with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "**Share your Kaggle profile link  with us here to score , points in  the competition.**\n",
    "\n",
    "**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n",
    "\n",
    "\n",
    "**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10665762,
     "sourceId": 90936,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
