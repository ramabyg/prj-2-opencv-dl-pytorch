{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">0.1 Clone git repository to Kaggle workspace</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'prj-2-opencv-dl-pytorch'...\n",
      "remote: Enumerating objects: 211, done.\u001b[K\n",
      "remote: Enumerating objects: 211, done.\u001b[K\n",
      "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
      "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
      "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
      "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
      "remote: Total 211 (delta 132), reused 145 (delta 70), pack-reused 0 (from 0)\u001b[K\n",
      "remote: Total 211 (delta 132), reused 145 (delta 70), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (211/211), 2.88 MiB | 18.57 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n",
      "Receiving objects: 100% (211/211), 2.88 MiB | 18.57 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n",
      "[OK] Repository cloned and added to path\n",
      "[OK] Repository cloned and added to path\n"
     ]
    }
   ],
   "source": [
    "g_inference_only = False\n",
    "\n",
    "#delete directory if exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists('prj-2-opencv-dl-pytorch'):\n",
    "    shutil.rmtree('prj-2-opencv-dl-pytorch')\n",
    "# Clone repository from GitHub\n",
    "!git clone https://github.com/ramabyg/prj-2-opencv-dl-pytorch.git\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/prj-2-opencv-dl-pytorch')\n",
    "\n",
    "print(\"[OK] Repository cloned and added to path\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">0.2 Import modules </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "from src.config import get_config\n",
    "from src.datamodule import KenyanFood13DataModule\n",
    "from src.model import KenyanFood13Classifier\n",
    "from src.trainer import train_model\n",
    "from src.utils import calculate_dataset_mean_std\n",
    "\n",
    "print(\"[OK] All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods, which will be used to get training and validation data loader.\n",
    "\n",
    "You need to write a custom dataset class to load data.\n",
    "\n",
    "**Note; There is   no separate validation data. , You will thus have to create your own validation set, by dividing the train data into train and validation data. Usually, we do 80:20 ratio for train and validation, respectively.**\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "    ....\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "def get_data(args1, *args):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Please refer to src/datamodule.py and src/dataset.py.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "**Define your configuration here.**\n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"/kaggle/input/opencv-pytorch-project-2-classification-round-3\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 70 epochs\n",
      "Model: efficientnetv2\n",
      "Learning rate: 3e-05\n",
      "Batch size: 8\n",
      "Freeze percentage: 0.0 (0.0 = all layers trainable)\n",
      "Optimizer: adamw\n",
      "Scheduler: cosine\n",
      "Early stopping: patience=15\n",
      "Device: cuda\n",
      "Output directory: /kaggle/working/output\n",
      "Batch Size: 8\n",
      "Using model-specific preprocessing for: efficientnetv2\n"
     ]
    }
   ],
   "source": [
    "from src.config import get_config\n",
    "# Get configurations (auto-detects Kaggle environment)\n",
    "# Phase 1 + Phase 2 (RandAugment) settings\n",
    "train_config, data_config, system_config = get_config(\n",
    "    num_epochs=70,           # Recommended for Phase 2 (with RandAugment)\n",
    "    batch_size=8,           # Reduced for memory efficiency with freeze_pct=0.0\n",
    "    # All other Phase 1+2 settings are now defaults:\n",
    "    # - freeze_pct=0.0 (train all layers)\n",
    "    # - learning_rate=0.0001 (optimal for freeze_pct=0.0)\n",
    "    # - optimizer=\"adamw\"\n",
    "    # - scheduler=\"cosine\"\n",
    "    # - label_smoothing=0.1 (in model)\n",
    "    # - RandAugment (in datamodule)\n",
    "    # - input_size=384 (memory-efficient)\n",
    "    use_scheduler=True,\n",
    "    scheduler=\"cosine\"\n",
    ")\n",
    "\n",
    "# Optional: Customize early stopping\n",
    "# train_config.early_stop_patience = 10  # More patient\n",
    "# train_config.use_early_stopping = False  # Disable completely\n",
    "\n",
    "print(f\"Training for {train_config.num_epochs} epochs\")\n",
    "print(f\"Model: {train_config.model_name}\")\n",
    "print(f\"Learning rate: {train_config.learning_rate}\")\n",
    "print(f\"Batch size: {train_config.batch_size}\")\n",
    "print(f\"Freeze percentage: {train_config.freeze_pct} (0.0 = all layers trainable)\")\n",
    "print(f\"Optimizer: {train_config.optimizer}\")\n",
    "print(f\"Scheduler: {train_config.scheduler if train_config.use_scheduler else 'none'}\")\n",
    "print(f\"Early stopping: patience={train_config.early_stop_patience}\")\n",
    "print(f\"Device: {system_config.device}\")\n",
    "print(f\"Output directory: {system_config.output_dir}\")\n",
    "print(f\"Batch Size: {train_config.batch_size}\")\n",
    "\n",
    "\n",
    "# Option 1: Use model-specific preprocessing (RECOMMENDED for pre-trained models)\n",
    "# This uses the exact same preprocessing (mean, std, resolution) as the original pre-training\n",
    "print(f\"Using model-specific preprocessing for: {train_config.model_name}\")\n",
    "\n",
    "# Option 2 (Alternative): Calculate from dataset (more accurate for custom stats)\n",
    "# mean, std = calculate_dataset_mean_std(\n",
    "#     annotations_file=data_config.annotations_file,\n",
    "#     img_dir=data_config.img_dir,\n",
    "#     sample_size=None  # Use more samples on Kaggle, None means use all images\n",
    "# )\n",
    "\n",
    "# Option 3 (Alternative): Use pre-computed values (fastest)\n",
    "# mean = [0.5672, 0.4663, 0.3659]\n",
    "# std = [0.2484, 0.2561, 0.2600]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using model-specific preprocessing: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "[OK] Data module created with 13 classes\n",
      "Loading pre-trained EfficientNetV2-S weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82.7M/82.7M [00:00<00:00, 204MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 21,458,488 / 21,458,488 parameters (100.0%)\n",
      "[OK] Model created: efficientnetv2\n"
     ]
    }
   ],
   "source": [
    "# Create data module with model-specific preprocessing\n",
    "data_module = KenyanFood13DataModule(\n",
    "    data_config=data_config,\n",
    "    model_name=train_config.model_name\n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "print(f\"[OK] Data module created with {data_module.num_classes} classes\")\n",
    "\n",
    "# Create model\n",
    "model = KenyanFood13Classifier(train_config, data_module.num_classes)\n",
    "\n",
    "print(f\"[OK] Model created: {train_config.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Diagnostics Start ---\n",
      "CSV columns: ['id', 'class']\n",
      "                     id       class\n",
      "0  14278962987112149800     githeri\n",
      "1  13190220095752321996       ugali\n",
      "2  10431803432626641638  kachumbari\n",
      "3   4222441716327528413     githeri\n",
      "4   2547906925836120627      matoke\n",
      "Detected label column: class\n",
      "class_to_idx mapping (sample): {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9}\n",
      "\n",
      "Label distribution (top counts):\n",
      "class\n",
      "chapati        862\n",
      "nyamachoma     784\n",
      "bhaji          632\n",
      "ugali          628\n",
      "mandazi        620\n",
      "kachumbari     494\n",
      "matoke         483\n",
      "githeri        479\n",
      "masalachips    438\n",
      "sukumawiki     402\n",
      "pilau          329\n",
      "mukimo         212\n",
      "kukuchoma      173\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train batch images shape: torch.Size([32, 3, 384, 384])\n",
      "Train batch labels shape: torch.Size([32])\n",
      "Sample label indices: [5, 9, 12, 5, 0, 0, 6, 5, 11, 7]\n",
      "Sample label names: ['mandazi', 'nyamachoma', 'ugali', 'mandazi', 'bhaji', 'bhaji', 'masalachips', 'mandazi', 'sukumawiki', 'matoke']\n",
      "Image min/max: -2.1179039478302 2.640000104904175\n",
      "Using device for diagnostics: cuda\n",
      "\n",
      "Train batch images shape: torch.Size([32, 3, 384, 384])\n",
      "Train batch labels shape: torch.Size([32])\n",
      "Sample label indices: [5, 9, 12, 5, 0, 0, 6, 5, 11, 7]\n",
      "Sample label names: ['mandazi', 'nyamachoma', 'ugali', 'mandazi', 'bhaji', 'bhaji', 'masalachips', 'mandazi', 'sukumawiki', 'matoke']\n",
      "Image min/max: -2.1179039478302 2.640000104904175\n",
      "Using device for diagnostics: cuda\n",
      "\n",
      "Model predictions (top1 indices): [7, 9, 7, 1, 9, 12, 2, 2, 3, 7, 3, 1, 10, 2, 2, 6, 7, 6, 9, 10, 2, 4, 11, 6, 0, 7, 1, 0, 11, 12, 9, 10]\n",
      "Model top confidences: [0.0935, 0.1174, 0.0958, 0.0991, 0.1013, 0.0925, 0.105, 0.0955, 0.0939, 0.0945, 0.0884, 0.0899, 0.1092, 0.1017, 0.1053, 0.0989, 0.1038, 0.0927, 0.0955, 0.097, 0.0999, 0.0984, 0.0896, 0.104, 0.0989, 0.104, 0.094, 0.0944, 0.1071, 0.1057, 0.1278, 0.0972]\n",
      "\n",
      "Data module mean/std: [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
      "--- Diagnostics End ---\n",
      "\n",
      "Model predictions (top1 indices): [7, 9, 7, 1, 9, 12, 2, 2, 3, 7, 3, 1, 10, 2, 2, 6, 7, 6, 9, 10, 2, 4, 11, 6, 0, 7, 1, 0, 11, 12, 9, 10]\n",
      "Model top confidences: [0.0935, 0.1174, 0.0958, 0.0991, 0.1013, 0.0925, 0.105, 0.0955, 0.0939, 0.0945, 0.0884, 0.0899, 0.1092, 0.1017, 0.1053, 0.0989, 0.1038, 0.0927, 0.0955, 0.097, 0.0999, 0.0984, 0.0896, 0.104, 0.0989, 0.104, 0.094, 0.0944, 0.1071, 0.1057, 0.1278, 0.0972]\n",
      "\n",
      "Data module mean/std: [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
      "--- Diagnostics End ---\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics: check labels, mapping, a sample batch and a model forward pass\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Diagnostics Start ---\")\n",
    "# Check CSV columns and a small preview\n",
    "try:\n",
    "    df = pd.read_csv(data_config.annotations_file)\n",
    "    print(\"CSV columns:\", list(df.columns))\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(\"Could not read annotations file:\", e)\n",
    "\n",
    "# Show detected label column and class mapping\n",
    "label_col = getattr(data_module.train_dataset, 'label_col', None)\n",
    "print(\"Detected label column:\", label_col)\n",
    "print(\"class_to_idx mapping (sample):\", dict(list(data_module.train_dataset.class_to_idx.items())[:10]))\n",
    "\n",
    "# Show label distribution (if available)\n",
    "try:\n",
    "    if label_col and label_col in df.columns:\n",
    "        print('\\nLabel distribution (top counts):')\n",
    "        print(df[label_col].value_counts().head(20))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Inspect a single batch from train loader\n",
    "train_loader = data_module.train_dataloader()\n",
    "images, labels = next(iter(train_loader))\n",
    "print('\\nTrain batch images shape:', images.shape)\n",
    "print('Train batch labels shape:', labels.shape)\n",
    "print('Sample label indices:', labels[:10].tolist())\n",
    "\n",
    "# Reverse mapping idx -> class name\n",
    "idx_to_class = {v: k for k, v in data_module.train_dataset.class_to_idx.items()}\n",
    "print('Sample label names:', [idx_to_class.get(int(x), '?') for x in labels[:10]])\n",
    "\n",
    "# Basic image stats (after preprocessing)\n",
    "print('Image min/max:', float(images.min()), float(images.max()))\n",
    "\n",
    "# Quick forward pass through model to inspect outputs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and system_config.device == 'cuda' else 'cpu')\n",
    "print('Using device for diagnostics:', device)\n",
    "model = model.to(device)\n",
    "images = images.to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    top1 = probs.argmax(dim=1).cpu().numpy().tolist()\n",
    "    top_conf_vals, _ = probs.max(dim=1)\n",
    "    top_conf = top_conf_vals.cpu().numpy().tolist()\n",
    "    # top_conf = probs.max(dim=1).cpu().numpy().tolist()\n",
    "\n",
    "print('\\nModel predictions (top1 indices):', top1)\n",
    "print('Model top confidences:', [round(float(x), 4) for x in top_conf])\n",
    "\n",
    "print('\\nData module mean/std:', data_module.mean, data_module.std)\n",
    "print('--- Diagnostics End ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "**Define methods or classes that will be used in model evaluation. For example, accuracy, f1-score etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Updated in trainer.py to include more metrics\n",
    "#we will have methods to calculate accuracy, f1-score, precision, recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "\n",
    "**Write the methods or classes to be used for training and validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping enabled: monitor=valid/acc, patience=15\n",
      "ğŸ“Š Detected 2 GPUs - Using DDP Notebook strategy\n",
      "âš ï¸  Note: If still using 1 GPU, Kaggle may need kernel restart\n",
      "\n",
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc009767a5d46a8a3068839e1344922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92d3cf8470f4bc19d8794197e702d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b49f4e1e8d4e3e9af709c7bc4d55d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29a6b9621d0417f8046a42e55657889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e0380619674d49ba1509c3fc402206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906f4ebe158d48b48d020c2d78732079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c608b87518a94bb4959e068988ccf5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048b3762914d460cbf16c9518cc8da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb4a8658b894d559ef7d0f7806b1d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f9c5bca73f44fdaaeae2cf4048aa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349cfff1d8cf459dacad7e0b8863264e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d61df86a2a4544be904dd64cf105e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852127f1e10d4fff8cbee9b1c5223336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4379e7066de540ffbb6d80ead52261fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9079a24b57047ac9a837528b5bad1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e828ec9d7b7f45818cb398acd2a6f901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac06cb1dc095493dadde4d3446232a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2045a538bd4fd692e03cfcb4c8063f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcadd8d7fdaa4288b2c5081bf2b3c9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4eb89b6e23048e2a4cf1b30d258bf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546dcdbcc3894a09ac7a7a674385eb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653e8fe12f8f4232ae122adf64a2b912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a32fc945649d2b39669124bedb99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f34034bac6f454db3868a95019658df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff91622da874eeea004dfc76290ad56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa32886815342b39a2def9b7bccf2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c0e7d164ef485eb006dbeb8ecc58a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3ef79adef3402183edb013036a61c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf544148036404599f0f3e22979b856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cd0d6239fb4abda96deee4b453e4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f007663c2ad4661a59019723f318d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c34449d20240868b998053d0c2ff78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58fe6f2159a42e2926675733b416521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ae46978bbc4500a9f5b6eeaabc3eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd57f32154749b6ae149f67d2f000c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58f30d3f8fa4ef58a57411ded0b308a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9735a6ebb194b2fb50b7266a965b640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fec2d7268146629be406dc70862ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a4e60b3fe4f3199e2d34a0af9286c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17593835a9b4344841be8fc8620b6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0180b8d8f94a7d8497f990f78a1c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323a58d11d354a09a92aae76bc085304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0788b530814c23be63d0f93cac0e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f790eec106c4040bda44a16c73d7eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01999aaa098429e8d9f04a8e846f9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61cd9e7b5464fd687f9191520d9bc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b5d5d89ce341fe9adc8dfb5454b077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384f96dd1c6d4f7ebd77bf44f32942b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c738604bc797464e8e353d40c19647ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038ae22d78634e9cbb5eb2ce2fe49bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5376a0a09e846fd94e28c094bea5328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59f5ef3e0a9468ea1865cb1b4b12501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76532a5ac1141938ef5d930bd013f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d451fb78e304c29ae9acd020f9debdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d669135077f46e0ac8f14ead2efbdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317a363be5a34a50865a92d3c6cac1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f12dcce9fec418e83c355e36f4dfda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running Final Validation\n",
      "============================================================\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98b22ce4e1a41e6a8e28a2e4af2876f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">      Validate metric      </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">           step            </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">           55.0            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         valid/acc         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8330965042114258     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         valid/f1          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8331873416900635     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">        valid/loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    1.0212222337722778     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">      valid/precision      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8354344367980957     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       valid/recall        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8330965042114258     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m          step           \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m          55.0           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        valid/acc        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8330965042114258    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        valid/f1         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8331873416900635    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m       valid/loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   1.0212222337722778    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m     valid/precision     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8354344367980957    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      valid/recall       \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8330965042114258    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best model saved to: /kaggle/working/output/checkpoints/39-0.8362.ckpt\n",
      "Best validation accuracy: 0.8362\n",
      "============================================================\n",
      "\n",
      "\n",
      "[OK] Training complete!\n",
      "Best model: /kaggle/working/output/checkpoints/39-0.8362.ckpt\n",
      "Best accuracy: 0.8362\n"
     ]
    }
   ],
   "source": [
    "if not g_inference_only:\n",
    "    # Train the model\n",
    "    trained_model, _, checkpoint_callback = train_model(\n",
    "        training_config=train_config,\n",
    "        data_config=data_config,\n",
    "        system_config=system_config,\n",
    "        model=model,\n",
    "        data_module=data_module\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[OK] Training complete!\")\n",
    "    print(f\"Best model: {checkpoint_callback.best_model_path}\")\n",
    "    print(f\"Best accuracy: {checkpoint_callback.best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "**Define your model in this section.**\n",
    "\n",
    "**You are allowed to use any pre-trained model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:  Using EfficientNet V2 S, please refer to ./src/model.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "**Define those methods or classes, which have  not been covered in the above sections.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save outputs to Kaggle output folder in a zip for easy download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best checkpoint: 39-0.8362.ckpt\n",
      "âœ“ Saved training summary\n",
      "Copying TensorBoard logs from /kaggle/working/output/kenyan_food_logs...\n",
      "âœ“ Saved TensorBoard logs (168.5 MB)\n",
      "\n",
      "Creating ZIP archive for download...\n",
      "âœ“ Saved TensorBoard logs (168.5 MB)\n",
      "\n",
      "Creating ZIP archive for download...\n",
      "âœ“ Created kenyan_food_model_output.zip (81.5 MB)\n",
      "\n",
      "============================================================\n",
      "[OK] OUTPUT READY FOR DOWNLOAD!\n",
      "============================================================\n",
      "\n",
      "Files saved to: /kaggle/working/kenyan_food_model_output/\n",
      "ZIP file: /kaggle/working/kenyan_food_model_output.zip\n",
      "\n",
      "Contents:\n",
      "  - best_model.ckpt           : Best model checkpoint\n",
      "  - training_summary.json     : Training metrics and config\n",
      "  - tensorboard_logs/         : Full TensorBoard event files\n",
      "\n",
      "To download:\n",
      "1. Click 'Output' tab in the right sidebar\n",
      "2. Find 'kenyan_food_model_output.zip'\n",
      "3. Click the download button\n",
      "\n",
      "Or use Kaggle API to create a dataset for reuse in other notebooks!\n",
      "============================================================\n",
      "âœ“ Created kenyan_food_model_output.zip (81.5 MB)\n",
      "\n",
      "============================================================\n",
      "[OK] OUTPUT READY FOR DOWNLOAD!\n",
      "============================================================\n",
      "\n",
      "Files saved to: /kaggle/working/kenyan_food_model_output/\n",
      "ZIP file: /kaggle/working/kenyan_food_model_output.zip\n",
      "\n",
      "Contents:\n",
      "  - best_model.ckpt           : Best model checkpoint\n",
      "  - training_summary.json     : Training metrics and config\n",
      "  - tensorboard_logs/         : Full TensorBoard event files\n",
      "\n",
      "To download:\n",
      "1. Click 'Output' tab in the right sidebar\n",
      "2. Find 'kenyan_food_model_output.zip'\n",
      "3. Click the download button\n",
      "\n",
      "Or use Kaggle API to create a dataset for reuse in other notebooks!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if not g_inference_only:\n",
    "    import json\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Create a clean output directory for the dataset\n",
    "    dataset_dir = Path(\"/kaggle/working/kenyan_food_model_output\")\n",
    "    if dataset_dir.exists():\n",
    "        shutil.rmtree(dataset_dir)\n",
    "    dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Copy the best checkpoint\n",
    "    best_checkpoint = Path(checkpoint_callback.best_model_path)\n",
    "    if best_checkpoint.exists():\n",
    "        shutil.copy(best_checkpoint, dataset_dir / \"best_model.ckpt\")\n",
    "        print(f\"âœ“ Saved best checkpoint: {best_checkpoint.name}\")\n",
    "\n",
    "    # Save training summary as JSON\n",
    "    summary = {\n",
    "        \"best_val_accuracy\": float(checkpoint_callback.best_model_score),\n",
    "        \"num_epochs\": train_config.num_epochs,\n",
    "        \"batch_size\": train_config.batch_size,\n",
    "        \"learning_rate\": train_config.learning_rate,\n",
    "        \"model\": train_config.model_name,\n",
    "        \"optimizer\": train_config.optimizer,\n",
    "        \"scheduler\": train_config.scheduler if train_config.use_scheduler else \"none\",\n",
    "        \"dataset_mean\": data_module.mean,\n",
    "        \"dataset_std\": data_module.std,\n",
    "        \"num_classes\": data_module.num_classes,\n",
    "        \"checkpoint_path\": str(best_checkpoint.name)\n",
    "    }\n",
    "\n",
    "    with open(dataset_dir / \"training_summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"âœ“ Saved training summary\")\n",
    "\n",
    "    # Copy ALL TensorBoard logs (full logs for offline review)\n",
    "    tb_logs_src = Path(system_config.output_dir) / \"kenyan_food_logs\"\n",
    "    if tb_logs_src.exists():\n",
    "        tb_logs_dest = dataset_dir / \"tensorboard_logs\"\n",
    "\n",
    "        print(f\"Copying TensorBoard logs from {tb_logs_src}...\")\n",
    "        shutil.copytree(tb_logs_src, tb_logs_dest, dirs_exist_ok=True)\n",
    "\n",
    "        # Count total size of logs for user info\n",
    "        total_size_bytes = sum(f.stat().st_size for f in tb_logs_dest.rglob('*') if f.is_file())\n",
    "        total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "        print(f\"âœ“ Saved TensorBoard logs ({total_size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"[WARN] TensorBoard logs not found at {tb_logs_src}\")\n",
    "\n",
    "    # Create a ZIP file for easy download\n",
    "    print(\"\\nCreating ZIP archive for download...\")\n",
    "    zip_path = Path(\"/kaggle/working/kenyan_food_model_output\")\n",
    "    shutil.make_archive(str(zip_path), 'zip', dataset_dir)\n",
    "    zip_size_mb = Path(f\"{zip_path}.zip\").stat().st_size / (1024 * 1024)\n",
    "    print(f\"âœ“ Created kenyan_food_model_output.zip ({zip_size_mb:.1f} MB)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[OK] OUTPUT READY FOR DOWNLOAD!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nFiles saved to: /kaggle/working/kenyan_food_model_output/\")\n",
    "    print(\"ZIP file: /kaggle/working/kenyan_food_model_output.zip\")\n",
    "    print(\"\\nContents:\")\n",
    "    print(\"  - best_model.ckpt           : Best model checkpoint\")\n",
    "    print(\"  - training_summary.json     : Training metrics and config\")\n",
    "    print(\"  - tensorboard_logs/         : Full TensorBoard event files\")\n",
    "    print(\"\\nTo download:\")\n",
    "    print(\"1. Click 'Output' tab in the right sidebar\")\n",
    "    print(\"2. Find 'kenyan_food_model_output.zip'\")\n",
    "    print(\"3. Click the download button\")\n",
    "    print(\"\\nOr use Kaggle API to create a dataset for reuse in other notebooks!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.a: Generate Test Predictions\n",
    "\n",
    "After training completes, generate predictions on test data and create submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained EfficientNetV2-S weights...\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 21,458,488 / 21,458,488 parameters (100.0%)\n",
      "[INFO] Using device: cuda\n",
      "[INFO] Loading model from checkpoint: /kaggle/working/output/checkpoints/39-0.8362.ckpt\n",
      "Loading pre-trained EfficientNetV2-S weights...\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 21,458,488 / 21,458,488 parameters (100.0%)\n",
      "[OK] Model loaded successfully\n",
      "[INFO] Using preprocessing for efficientnetv2: size=384, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
      "[INFO] Loading test dataset from /kaggle/input/opencv-pytorch-project-2-classification-round-3/test.csv\n",
      "[INFO] Test mode: Loading 1638 test samples (no labels)\n",
      "[INFO] CSV columns: ['id']\n",
      "[INFO] Test dataset size: 1638\n",
      "[INFO] Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [01:11<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1638 predictions\n",
      "[INFO] Loading class mapping from training data...\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[OK] Loaded class mapping with 13 classes\n",
      "[OK] Submission saved to: /kaggle/working/submission.csv\n",
      "[INFO] Submission shape: (1638, 2)\n",
      "[INFO] Sample predictions:\n",
      "                     id        class\n",
      "0   9156739011499789258   nyamachoma\n",
      "1   2049465964503133373   kachumbari\n",
      "2   6446998501027132988   nyamachoma\n",
      "3   4194396063119815321        ugali\n",
      "4   9018117998187006009   kachumbari\n",
      "5   6246759883907852128  masalachips\n",
      "6  16478122708528316044   nyamachoma\n",
      "7  14045745760440690312        pilau\n",
      "8   7872954221890963019       matoke\n",
      "9   4868486697531317477      chapati\n",
      "\n",
      "[INFO] Prediction distribution:\n",
      "class\n",
      "chapati        226\n",
      "nyamachoma     193\n",
      "ugali          184\n",
      "bhaji          155\n",
      "mandazi        153\n",
      "matoke         122\n",
      "githeri        118\n",
      "masalachips    115\n",
      "kachumbari     110\n",
      "sukumawiki      97\n",
      "Name: count, dtype: int64\n",
      "[OK] Submission created: /kaggle/working/submission.csv\n",
      "[INFO] Total predictions: 1638\n",
      "\n",
      "[INFO] Prediction distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0a951c9b0045>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[INFO] Total predictions: {len(submission_df)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n[INFO] Prediction distribution:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[OK] Ready to download and submit to Kaggle!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "from src.inference import create_submission\n",
    "if g_inference_only:\n",
    "    checkpoint_path = \"/kaggle/working/kenyan_food_model_output/best_model.ckpt\"\n",
    "else:\n",
    "    checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "# Generate predictions and create submission.csv\n",
    "# Automatically detects Kaggle environment and uses correct paths\n",
    "submission_df = create_submission(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    output_csv_path=\"/kaggle/working/submission.csv\",\n",
    "    model_config=train_config,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "print(f\"[OK] Submission created: /kaggle/working/submission.csv\")\n",
    "print(f\"[INFO] Total predictions: {len(submission_df)}\")\n",
    "print(f\"\\n[INFO] Prediction distribution:\")\n",
    "print(submission_df['label'].value_counts())\n",
    "print(\"\\n[OK] Ready to download and submit to Kaggle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Experiment [5 Points]</font>\n",
    "\n",
    "**Choose your optimizer and LR-scheduler and use the above methods and classes to train your model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Updated in src/trainer.py module.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Log Link [5 Points]</font>\n",
    "\n",
    "**Share your TensorBoard scalars logs link here You can also share (not mandatory) your GitHub link, if you have pushed this project in GitHub.**\n",
    "\n",
    "\n",
    "Note: In light of the recent shutdown of tensorboard.dev, we have updated the submission requirements for your project. Instead of sharing a tensorboard.dev link, you are now required to upload your generated TensorBoard event files directly onto the lab. As an alternative, you may also include a screenshot of your TensorBoard output within your Jupyter notebook. This adjustment ensures that your data visualization and model training efforts are thoroughly documented and accessible for evaluation.\n",
    "\n",
    "You are also welcome (and encouraged) to utilize alternative logging services like wandB or comet. In such instances, you can easily make your project logs publicly accessible and share the link with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Will upload the logs along with this code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "**Share your Kaggle profile link  with us here to score , points in  the competition.**\n",
    "\n",
    "**For full points, you need a minimum accuracy of `75%` on the test data. If accuracy is less than `70%`, you gain  no points for this section.**\n",
    "\n",
    "\n",
    "**Submit `submission.csv` (prediction for images in `test.csv`), in the `Submit Predictions` tab in Kaggle, to get evaluated for  this section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Rama Kaggle Profile](https://www.kaggle.com/ramabyg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10665762,
     "sourceId": 90936,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
