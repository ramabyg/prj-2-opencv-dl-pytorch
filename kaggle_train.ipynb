{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce9fd3",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository (Kaggle Only)\n",
    "\n",
    "Run this cell on Kaggle to get the latest code from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cbce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'prj-2-opencv-dl-pytorch'...\n",
      "remote: Enumerating objects: 100, done.\u001b[K\n",
      "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Enumerating objects: 100, done.\u001b[K\n",
      "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 100 (delta 51), reused 72 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (100/100), 1.38 MiB | 11.75 MiB/s, done.\n",
      "Resolving deltas: 100% (51/51), done.\n",
      "remote: Total 100 (delta 51), reused 72 (delta 27), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (100/100), 1.38 MiB | 11.75 MiB/s, done.\n",
      "Resolving deltas: 100% (51/51), done.\n",
      "‚úì Repository cloned and added to path\n",
      "‚úì Repository cloned and added to path\n"
     ]
    }
   ],
   "source": [
    "#delete directory if exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists('prj-2-opencv-dl-pytorch'):\n",
    "    shutil.rmtree('prj-2-opencv-dl-pytorch')\n",
    "# Clone repository from GitHub\n",
    "!git clone https://github.com/ramabyg/prj-2-opencv-dl-pytorch.git\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/prj-2-opencv-dl-pytorch')\n",
    "\n",
    "print(\"‚úì Repository cloned and added to path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f0eea",
   "metadata": {},
   "source": [
    "## Step 2: Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3432eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "from src.config import get_config\n",
    "from src.datamodule import KenyanFood13DataModule\n",
    "from src.model import KenyanFood13Classifier\n",
    "from src.trainer import train_model\n",
    "from src.utils import calculate_dataset_mean_std\n",
    "\n",
    "print(\"‚úì All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412f178",
   "metadata": {},
   "source": [
    "## Step 3: Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8216c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 epochs\n",
      "Batch size: 32\n",
      "Device: cuda\n",
      "Output directory: /kaggle/working/output\n"
     ]
    }
   ],
   "source": [
    "# Get configurations (auto-detects Kaggle environment)\n",
    "train_config, data_config, system_config = get_config(\n",
    "    num_epochs=100,          # Adjust as needed\n",
    "    batch_size=32,           # Larger batch for multi-GPU\n",
    "    learning_rate=0.001,\n",
    "    use_scheduler=True,\n",
    "    scheduler=\"cosine\"\n",
    ")\n",
    "\n",
    "print(f\"Training for {train_config.num_epochs} epochs\")\n",
    "print(f\"Batch size: {train_config.batch_size}\")\n",
    "print(f\"Device: {system_config.device}\")\n",
    "print(f\"Output directory: {system_config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa728d",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Dataset Statistics (Optional)\n",
    "\n",
    "You can skip this and use ImageNet defaults for faster startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b900ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Calculate from dataset (more accurate)\n",
    "# mean, std = calculate_dataset_mean_std(\n",
    "#     annotations_file=data_config.annotations_file,\n",
    "#     img_dir=data_config.img_dir,\n",
    "#     sample_size=None  # Use more samples on Kaggle, None means use all images\n",
    "# )\n",
    "\n",
    "# Option 2: Use ImageNet defaults (faster)\n",
    "# from src.utils import get_imagenet_stats\n",
    "# mean, std = get_imagenet_stats()\n",
    "\n",
    "#Option 3: Use pre computed values (fastest)\n",
    "mean = [0.5672, 0.4663, 0.3659]\n",
    "std = [0.2484, 0.2561, 0.2600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e65433",
   "metadata": {},
   "source": [
    "## Step 5: Create Data Module and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdaade51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5228 samples for training.\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "Using 1308 samples for validation.\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "‚úì Data module created with 13 classes\n",
      "Loading pre-trained GoogleNet weights...\n",
      "‚úì Pre-trained weights loaded successfully\n",
      "‚úì Model created: googlenet\n",
      "‚úì Pre-trained weights loaded successfully\n",
      "‚úì Model created: googlenet\n"
     ]
    }
   ],
   "source": [
    "# Create data module\n",
    "data_module = KenyanFood13DataModule(data_config, mean=mean, std=std)\n",
    "data_module.setup()\n",
    "\n",
    "print(f\"‚úì Data module created with {data_module.num_classes} classes\")\n",
    "\n",
    "# Create model\n",
    "model = KenyanFood13Classifier(train_config, data_module.num_classes)\n",
    "\n",
    "print(f\"‚úì Model created: {train_config.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9958a4",
   "metadata": {},
   "source": [
    "## Step 6: Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cc9310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Detected 2 GPUs - Using DDP Notebook strategy\n",
      "‚ö†Ô∏è  Note: If still using 1 GPU, Kaggle may need kernel restart\n",
      "\n",
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Lightning can't create new processes if CUDA is already initialized. Did you manually call `torch.cuda.*` functions, have moved the model to the device, or allocated memory on the GPU any other way? Please remove any such calls, or change the selected strategy. You will have to restart the Python kernel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c5059ab8b07b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trained_model, _, checkpoint_callback = train_model(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msystem_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/prj-2-opencv-dl-pytorch/src/trainer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_config, data_config, system_config, model, data_module)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"fork\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"forkserver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0m_check_bad_cuda_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spawn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0m_check_missing_main_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning_fabric/strategies/launchers/multiprocessing.py\u001b[0m in \u001b[0;36m_check_bad_cuda_fork\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_IS_INTERACTIVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" You will have to restart the Python kernel.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Lightning can't create new processes if CUDA is already initialized. Did you manually call `torch.cuda.*` functions, have moved the model to the device, or allocated memory on the GPU any other way? Please remove any such calls, or change the selected strategy. You will have to restart the Python kernel."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model, _, checkpoint_callback = train_model(\n",
    "    training_config=train_config,\n",
    "    data_config=data_config,\n",
    "    system_config=system_config,\n",
    "    model=model,\n",
    "    data_module=data_module\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Training complete!\")\n",
    "print(f\"Best model: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"Best accuracy: {checkpoint_callback.best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f4f58",
   "metadata": {},
   "source": [
    "## Step 7: Save Outputs to Kaggle Dataset\n",
    "\n",
    "This will save your trained model and training summary to a Kaggle Dataset for easy access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187739b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a clean output directory for the dataset\n",
    "dataset_dir = Path(\"/kaggle/working/kenyan_food_model_output\")\n",
    "if dataset_dir.exists():\n",
    "    shutil.rmtree(dataset_dir)\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy the best checkpoint\n",
    "best_checkpoint = Path(checkpoint_callback.best_model_path)\n",
    "if best_checkpoint.exists():\n",
    "    shutil.copy(best_checkpoint, dataset_dir / \"best_model.ckpt\")\n",
    "    print(f\"‚úì Saved best checkpoint: {best_checkpoint.name}\")\n",
    "\n",
    "# Save training summary as JSON\n",
    "summary = {\n",
    "    \"best_val_accuracy\": float(checkpoint_callback.best_model_score),\n",
    "    \"num_epochs\": train_config.num_epochs,\n",
    "    \"batch_size\": train_config.batch_size,\n",
    "    \"learning_rate\": train_config.learning_rate,\n",
    "    \"model\": train_config.model_name,\n",
    "    \"optimizer\": train_config.optimizer,\n",
    "    \"scheduler\": train_config.scheduler if train_config.use_scheduler else \"none\",\n",
    "    \"dataset_mean\": mean,\n",
    "    \"dataset_std\": std,\n",
    "    \"num_classes\": data_module.num_classes,\n",
    "    \"checkpoint_path\": str(best_checkpoint.name)\n",
    "}\n",
    "\n",
    "with open(dataset_dir / \"training_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"‚úì Saved training summary\")\n",
    "\n",
    "# Copy ALL TensorBoard logs (full logs for offline review)\n",
    "tb_logs_src = Path(system_config.output_dir) / \"kenyan_food_logs\"\n",
    "if tb_logs_src.exists():\n",
    "    tb_logs_dest = dataset_dir / \"tensorboard_logs\"\n",
    "\n",
    "    print(f\"Copying TensorBoard logs from {tb_logs_src}...\")\n",
    "    shutil.copytree(tb_logs_src, tb_logs_dest, dirs_exist_ok=True)\n",
    "\n",
    "    # Calculate total size\n",
    "    total_size = sum(f.stat().st_size for f in tb_logs_dest.rglob('*') if f.is_file())\n",
    "    print(f\"‚úì Saved TensorBoard logs ({total_size / 1_000_000:.1f} MB)\")\n",
    "else:\n",
    "    print(\"‚ö† No TensorBoard logs found\")\n",
    "\n",
    "# Create a ZIP file for easy download\n",
    "print(\"\\nCreating ZIP file...\")\n",
    "zip_path = Path(\"/kaggle/working/kenyan_food_model_output.zip\")\n",
    "if zip_path.exists():\n",
    "    zip_path.unlink()\n",
    "\n",
    "shutil.make_archive(\n",
    "    str(zip_path.with_suffix('')),  # Remove .zip, make_archive adds it\n",
    "    'zip',\n",
    "    dataset_dir\n",
    ")\n",
    "\n",
    "zip_size = zip_path.stat().st_size / 1_000_000\n",
    "print(f\"‚úì Created ZIP file: {zip_path.name} ({zip_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Output saved to: {dataset_dir}\")\n",
    "print(f\"ZIP file: {zip_path}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nWhat's saved:\")\n",
    "print(f\"  - best_model.ckpt (trained model)\")\n",
    "print(f\"  - training_summary.json (metrics & config)\")\n",
    "print(f\"  - tensorboard_logs/ (full logs for offline review)\")\n",
    "print(\"\\nDownload options:\")\n",
    "print(\"  Option 1: Download ZIP directly from Output tab\")\n",
    "print(\"    ‚Üí Look for 'kenyan_food_model_output.zip'\")\n",
    "print(\"    ‚Üí Click to download (single file, faster)\")\n",
    "print(\"\\n  Option 2: Create as Kaggle Dataset\")\n",
    "print(\"    1. Click 'Save Version' in Kaggle (top right)\")\n",
    "print(\"    2. After run completes, go to 'Output' tab\")\n",
    "print(\"    3. Click 'New Dataset' and name it (e.g., 'kenyan-food-model-v1')\")\n",
    "print(\"    4. Reusable in other notebooks!\")\n",
    "print(\"\\nTo view TensorBoard logs locally:\")\n",
    "print(\"  1. Extract the ZIP file\")\n",
    "print(\"  2. Run: tensorboard --logdir=kenyan_food_model_output/tensorboard_logs\")\n",
    "print(\"  3. Open: http://localhost:6006\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284f858",
   "metadata": {},
   "source": [
    "## Step 8: Generate Predictions (TODO)\n",
    "\n",
    "Add your inference code here to generate submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load test data and generate predictions\n",
    "# TODO: Create submission.csv\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
