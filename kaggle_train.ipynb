{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce9fd3",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository (Kaggle Only)\n",
    "\n",
    "Run this cell on Kaggle to get the latest code from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cbce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'prj-2-opencv-dl-pytorch'...\n",
      "remote: Enumerating objects: 169, done.\u001b[K\n",
      "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
      "remote: Enumerating objects: 169, done.\u001b[K\u001b[K\n",
      "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
      "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
      "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
      "remote: Total 169 (delta 100), reused 118 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (169/169), 2.86 MiB | 17.78 MiB/s, done.\n",
      "Resolving deltas: 100% (100/100), done.\n",
      "remote: Total 169 (delta 100), reused 118 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (169/169), 2.86 MiB | 17.78 MiB/s, done.\n",
      "Resolving deltas: 100% (100/100), done.\n",
      "[OK] Repository cloned and added to path\n",
      "[OK] Repository cloned and added to path\n"
     ]
    }
   ],
   "source": [
    "g_inference_only = False\n",
    "\n",
    "#delete directory if exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists('prj-2-opencv-dl-pytorch'):\n",
    "    shutil.rmtree('prj-2-opencv-dl-pytorch')\n",
    "# Clone repository from GitHub\n",
    "!git clone https://github.com/ramabyg/prj-2-opencv-dl-pytorch.git\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/prj-2-opencv-dl-pytorch')\n",
    "\n",
    "print(\"[OK] Repository cloned and added to path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f0eea",
   "metadata": {},
   "source": [
    "## Step 2: Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3432eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "from src.config import get_config\n",
    "from src.datamodule import KenyanFood13DataModule\n",
    "from src.model import KenyanFood13Classifier\n",
    "from src.trainer import train_model\n",
    "from src.utils import calculate_dataset_mean_std\n",
    "\n",
    "print(\"[OK] All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412f178",
   "metadata": {},
   "source": [
    "## Step 3: Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8216c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50 epochs\n",
      "Model: efficientnetv2\n",
      "Learning rate: 0.0003\n",
      "Batch size: 32\n",
      "Early stopping: patience=7\n",
      "Device: cuda\n",
      "Output directory: /kaggle/working/output\n"
     ]
    }
   ],
   "source": [
    "# Get configurations (auto-detects Kaggle environment)\n",
    "# Uses ResNet50 by default (better than GoogleNet)\n",
    "train_config, data_config, system_config = get_config(\n",
    "    num_epochs=10,            # Adjust as needed\n",
    "    batch_size=32,           # For single GPU\n",
    "    # learning_rate is now 0.0003 by default (better for fine-tuning)\n",
    "    use_scheduler=True,\n",
    "    scheduler=\"cosine\"\n",
    ")\n",
    "\n",
    "# Optional: Customize early stopping\n",
    "# train_config.early_stop_patience = 10  # More patient\n",
    "# train_config.use_early_stopping = False  # Disable completely\n",
    "\n",
    "print(f\"Training for {train_config.num_epochs} epochs\")\n",
    "print(f\"Model: {train_config.model_name}\")\n",
    "print(f\"Learning rate: {train_config.learning_rate}\")\n",
    "print(f\"Batch size: {train_config.batch_size}\")\n",
    "print(f\"Early stopping: patience={train_config.early_stop_patience}\")\n",
    "print(f\"Device: {system_config.device}\")\n",
    "print(f\"Output directory: {system_config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa728d",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Dataset Statistics (Optional)\n",
    "\n",
    "You can skip this and use ImageNet defaults for faster startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b900ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model-specific preprocessing for: efficientnetv2\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Use model-specific preprocessing (RECOMMENDED for pre-trained models)\n",
    "# This uses the exact same preprocessing (mean, std, resolution) as the original pre-training\n",
    "print(f\"Using model-specific preprocessing for: {train_config.model_name}\")\n",
    "\n",
    "# Option 2 (Alternative): Calculate from dataset (more accurate for custom stats)\n",
    "# mean, std = calculate_dataset_mean_std(\n",
    "#     annotations_file=data_config.annotations_file,\n",
    "#     img_dir=data_config.img_dir,\n",
    "#     sample_size=None  # Use more samples on Kaggle, None means use all images\n",
    "# )\n",
    "\n",
    "# Option 3 (Alternative): Use pre-computed values (fastest)\n",
    "# mean = [0.5672, 0.4663, 0.3659]\n",
    "# std = [0.2484, 0.2561, 0.2600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e65433",
   "metadata": {},
   "source": [
    "## Step 5: Create Data Module and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdaade51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using model-specific input size: 384 (was 224)\n",
      "[INFO] Using model-specific preprocessing: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "[OK] Data module created with 13 classes\n",
      "Loading pre-trained EfficientNetV2-S weights...\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 20,233,520 / 21,458,488 parameters (94.3%)\n",
      "[OK] Model created: efficientnetv2\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 20,233,520 / 21,458,488 parameters (94.3%)\n",
      "[OK] Model created: efficientnetv2\n"
     ]
    }
   ],
   "source": [
    "# Create data module with model-specific preprocessing\n",
    "data_module = KenyanFood13DataModule(\n",
    "    data_config=data_config,\n",
    "    model_name=train_config.model_name\n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "print(f\"[OK] Data module created with {data_module.num_classes} classes\")\n",
    "\n",
    "# Create model\n",
    "model = KenyanFood13Classifier(train_config, data_module.num_classes)\n",
    "\n",
    "print(f\"[OK] Model created: {train_config.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ac79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Diagnostics Start ---\n",
      "CSV columns: ['id', 'class']\n",
      "                     id       class\n",
      "0  14278962987112149800     githeri\n",
      "1  13190220095752321996       ugali\n",
      "2  10431803432626641638  kachumbari\n",
      "3   4222441716327528413     githeri\n",
      "4   2547906925836120627      matoke\n",
      "Detected label column: class\n",
      "class_to_idx mapping (sample): {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9}\n",
      "\n",
      "Label distribution (top counts):\n",
      "class\n",
      "chapati        862\n",
      "nyamachoma     784\n",
      "bhaji          632\n",
      "ugali          628\n",
      "mandazi        620\n",
      "kachumbari     494\n",
      "matoke         483\n",
      "githeri        479\n",
      "masalachips    438\n",
      "sukumawiki     402\n",
      "pilau          329\n",
      "mukimo         212\n",
      "kukuchoma      173\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train batch images shape: torch.Size([32, 3, 384, 384])\n",
      "Train batch labels shape: torch.Size([32])\n",
      "Sample label indices: [0, 4, 1, 7, 10, 9, 7, 7, 9, 1]\n",
      "Sample label names: ['bhaji', 'kukuchoma', 'chapati', 'matoke', 'pilau', 'nyamachoma', 'matoke', 'matoke', 'nyamachoma', 'chapati']\n",
      "Image min/max: -2.1179039478302 2.640000104904175\n",
      "Using device for diagnostics: cuda\n",
      "\n",
      "Train batch images shape: torch.Size([32, 3, 384, 384])\n",
      "Train batch labels shape: torch.Size([32])\n",
      "Sample label indices: [0, 4, 1, 7, 10, 9, 7, 7, 9, 1]\n",
      "Sample label names: ['bhaji', 'kukuchoma', 'chapati', 'matoke', 'pilau', 'nyamachoma', 'matoke', 'matoke', 'nyamachoma', 'chapati']\n",
      "Image min/max: -2.1179039478302 2.640000104904175\n",
      "Using device for diagnostics: cuda\n",
      "\n",
      "Model predictions (top1 indices): [1, 5, 0, 10, 1, 8, 1, 10, 10, 10, 10, 11, 11, 1, 3, 1, 2, 3, 1, 1, 3, 4, 8, 1, 8, 10, 1, 3, 3, 8, 10, 3]\n",
      "Model top confidences: [0.0988, 0.1109, 0.092, 0.0976, 0.1041, 0.1017, 0.1047, 0.097, 0.102, 0.0993, 0.1031, 0.0942, 0.0898, 0.0986, 0.1263, 0.1136, 0.1122, 0.1105, 0.1277, 0.1031, 0.1388, 0.1101, 0.1033, 0.0918, 0.1417, 0.1196, 0.1091, 0.1155, 0.1123, 0.1524, 0.1013, 0.102]\n",
      "\n",
      "Data module mean/std: [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
      "--- Diagnostics End ---\n",
      "\n",
      "Model predictions (top1 indices): [1, 5, 0, 10, 1, 8, 1, 10, 10, 10, 10, 11, 11, 1, 3, 1, 2, 3, 1, 1, 3, 4, 8, 1, 8, 10, 1, 3, 3, 8, 10, 3]\n",
      "Model top confidences: [0.0988, 0.1109, 0.092, 0.0976, 0.1041, 0.1017, 0.1047, 0.097, 0.102, 0.0993, 0.1031, 0.0942, 0.0898, 0.0986, 0.1263, 0.1136, 0.1122, 0.1105, 0.1277, 0.1031, 0.1388, 0.1101, 0.1033, 0.0918, 0.1417, 0.1196, 0.1091, 0.1155, 0.1123, 0.1524, 0.1013, 0.102]\n",
      "\n",
      "Data module mean/std: [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
      "--- Diagnostics End ---\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics: check labels, mapping, a sample batch and a model forward pass\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Diagnostics Start ---\")\n",
    "# Check CSV columns and a small preview\n",
    "try:\n",
    "    df = pd.read_csv(data_config.annotations_file)\n",
    "    print(\"CSV columns:\", list(df.columns))\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(\"Could not read annotations file:\", e)\n",
    "\n",
    "# Show detected label column and class mapping\n",
    "label_col = getattr(data_module.train_dataset, 'label_col', None)\n",
    "print(\"Detected label column:\", label_col)\n",
    "print(\"class_to_idx mapping (sample):\", dict(list(data_module.train_dataset.class_to_idx.items())[:10]))\n",
    "\n",
    "# Show label distribution (if available)\n",
    "try:\n",
    "    if label_col and label_col in df.columns:\n",
    "        print('\\nLabel distribution (top counts):')\n",
    "        print(df[label_col].value_counts().head(20))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Inspect a single batch from train loader\n",
    "train_loader = data_module.train_dataloader()\n",
    "images, labels = next(iter(train_loader))\n",
    "print('\\nTrain batch images shape:', images.shape)\n",
    "print('Train batch labels shape:', labels.shape)\n",
    "print('Sample label indices:', labels[:10].tolist())\n",
    "\n",
    "# Reverse mapping idx -> class name\n",
    "idx_to_class = {v: k for k, v in data_module.train_dataset.class_to_idx.items()}\n",
    "print('Sample label names:', [idx_to_class.get(int(x), '?') for x in labels[:10]])\n",
    "\n",
    "# Basic image stats (after preprocessing)\n",
    "print('Image min/max:', float(images.min()), float(images.max()))\n",
    "\n",
    "# Quick forward pass through model to inspect outputs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and system_config.device == 'cuda' else 'cpu')\n",
    "print('Using device for diagnostics:', device)\n",
    "model = model.to(device)\n",
    "images = images.to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(images)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    top1 = probs.argmax(dim=1).cpu().numpy().tolist()\n",
    "    top_conf_vals, _ = probs.max(dim=1)\n",
    "    top_conf = top_conf_vals.cpu().numpy().tolist()\n",
    "    # top_conf = probs.max(dim=1).cpu().numpy().tolist()\n",
    "\n",
    "print('\\nModel predictions (top1 indices):', top1)\n",
    "print('Model top confidences:', [round(float(x), 4) for x in top_conf])\n",
    "\n",
    "print('\\nData module mean/std:', data_module.mean, data_module.std)\n",
    "print('--- Diagnostics End ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9958a4",
   "metadata": {},
   "source": [
    "## Step 6: Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cc9310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping enabled: monitor=valid/acc, patience=7\n",
      "ğŸ“Š Detected 2 GPUs - Using DDP Notebook strategy\n",
      "âš ï¸  Note: If still using 1 GPU, Kaggle may need kernel restart\n",
      "\n",
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/output/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f0625222614134b0c53f0cd0dc14a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f556bf4370d04bfd87a0e9d60b7d18d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace11799bac9493b9b60f9d309118eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5725c477c8e04ea7a506a9d74482c557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9706c9ee3eb240f5824264c9e14859a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f428990c1f49edae6c914c184fe121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b426f3e24bff4f08abf159478da1984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74281d0f27d5453794240665c0b8ad51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712dc9dcc39d4072b26e5c086482180f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7e86e435224867b29a394aa5f3a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b5c5e464834e719800c34080e3812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1ce8fb6d40465d9144748778be1e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e778d0b9f9f64f1b8359c2da0a92ce4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70da0f91ec324bfb8d305bd1c38f3fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ffeffab6f84665bb68a2926dd7bae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3111051253b1468cb1857dedd83e0e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6921a99825d49db86800901cde9824b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bd0e66dc2844408609445d4f08d895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224a1eeede704176a4a0f4410e2b58ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d3f20c80154c62b8c10266640b94e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231930c111854d6ab7d1d91b7cc24554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818f483394fb4856b116ba708cc5c468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cdabfea44a43b4825a8ebed5ce6293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ac0b5baae34baa998823f852f27df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8ffbd9fcbd47b490bd08d5f3c949c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6171bb1b6e324ffca024523edd26175c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9450e428b8544086a4a8d6eeafa89d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79f4a7402394f6b8d420029bf72ce70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0152e16fe0d24c8ab28b5acfdcfbda85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ee1fb9a9e34023bec46e15a3a9812c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e70513b022e451daa6654fa9d989f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299d5c01e576481285a14f565656c787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0106d54488486a996d312de9114698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac5168da9fb4ad19ddd8059f8d3564f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5179e0578c4b56afe20936a159dee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b998c0a3b2d54bbaba02b2d53b8f94f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61871b774c9445669b753323d16ecce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e8e449405a470087ff854af8771c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34774a9f72e243ed986391e79b283399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c6a8e814fa4598b4578145760c449c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1b213fe6634e9da01b10bd69590b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782a7a5a9bfb4d64a46ab83d00db719b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running Final Validation\n",
      "============================================================\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 1308 samples for validation.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe7a1284b2c4914ac6464977cebedfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">      Validate metric      </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">           step            </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">           40.0            </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         valid/acc         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8234679698944092     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         valid/f1          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8293907642364502     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">        valid/loss         </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9930640459060669     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">      valid/precision      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8476113677024841     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">       valid/recall        </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.8234679698944092     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m          step           \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m          40.0           \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        valid/acc        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8234679698944092    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        valid/f1         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8293907642364502    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m       valid/loss        \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9930640459060669    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m     valid/precision     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8476113677024841    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m      valid/recall       \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.8234679698944092    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best model saved to: /kaggle/working/output/checkpoints/32-0.8257.ckpt\n",
      "Best validation accuracy: 0.8257\n",
      "============================================================\n",
      "\n",
      "\n",
      "[OK] Training complete!\n",
      "Best model: /kaggle/working/output/checkpoints/32-0.8257.ckpt\n",
      "Best accuracy: 0.8257\n"
     ]
    }
   ],
   "source": [
    "if not g_inference_only:\n",
    "    # Train the model\n",
    "    trained_model, _, checkpoint_callback = train_model(\n",
    "        training_config=train_config,\n",
    "        data_config=data_config,\n",
    "        system_config=system_config,\n",
    "        model=model,\n",
    "        data_module=data_module\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[OK] Training complete!\")\n",
    "    print(f\"Best model: {checkpoint_callback.best_model_path}\")\n",
    "    print(f\"Best accuracy: {checkpoint_callback.best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f4f58",
   "metadata": {},
   "source": [
    "## Step 7: Save Outputs to Kaggle Dataset\n",
    "\n",
    "This will save your trained model and training summary to a Kaggle Dataset for easy access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187739b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved best checkpoint: 32-0.8257.ckpt\n",
      "âœ“ Saved training summary\n",
      "Copying TensorBoard logs from /kaggle/working/output/kenyan_food_logs...\n",
      "âœ“ Saved TensorBoard logs (121.0 MB)\n",
      "\n",
      "Creating ZIP archive for download...\n",
      "âœ“ Saved TensorBoard logs (121.0 MB)\n",
      "\n",
      "Creating ZIP archive for download...\n",
      "âœ“ Created kenyan_food_model_output.zip (79.1 MB)\n",
      "\n",
      "============================================================\n",
      "[OK] OUTPUT READY FOR DOWNLOAD!\n",
      "============================================================\n",
      "\n",
      "Files saved to: /kaggle/working/kenyan_food_model_output/\n",
      "ZIP file: /kaggle/working/kenyan_food_model_output.zip\n",
      "\n",
      "Contents:\n",
      "  - best_model.ckpt           : Best model checkpoint\n",
      "  - training_summary.json     : Training metrics and config\n",
      "  - tensorboard_logs/         : Full TensorBoard event files\n",
      "\n",
      "To download:\n",
      "1. Click 'Output' tab in the right sidebar\n",
      "2. Find 'kenyan_food_model_output.zip'\n",
      "3. Click the download button\n",
      "\n",
      "Or use Kaggle API to create a dataset for reuse in other notebooks!\n",
      "============================================================\n",
      "âœ“ Created kenyan_food_model_output.zip (79.1 MB)\n",
      "\n",
      "============================================================\n",
      "[OK] OUTPUT READY FOR DOWNLOAD!\n",
      "============================================================\n",
      "\n",
      "Files saved to: /kaggle/working/kenyan_food_model_output/\n",
      "ZIP file: /kaggle/working/kenyan_food_model_output.zip\n",
      "\n",
      "Contents:\n",
      "  - best_model.ckpt           : Best model checkpoint\n",
      "  - training_summary.json     : Training metrics and config\n",
      "  - tensorboard_logs/         : Full TensorBoard event files\n",
      "\n",
      "To download:\n",
      "1. Click 'Output' tab in the right sidebar\n",
      "2. Find 'kenyan_food_model_output.zip'\n",
      "3. Click the download button\n",
      "\n",
      "Or use Kaggle API to create a dataset for reuse in other notebooks!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if not g_inference_only:\n",
    "    import json\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Create a clean output directory for the dataset\n",
    "    dataset_dir = Path(\"/kaggle/working/kenyan_food_model_output\")\n",
    "    if dataset_dir.exists():\n",
    "        shutil.rmtree(dataset_dir)\n",
    "    dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Copy the best checkpoint\n",
    "    best_checkpoint = Path(checkpoint_callback.best_model_path)\n",
    "    if best_checkpoint.exists():\n",
    "        shutil.copy(best_checkpoint, dataset_dir / \"best_model.ckpt\")\n",
    "        print(f\"âœ“ Saved best checkpoint: {best_checkpoint.name}\")\n",
    "\n",
    "    # Save training summary as JSON\n",
    "    summary = {\n",
    "        \"best_val_accuracy\": float(checkpoint_callback.best_model_score),\n",
    "        \"num_epochs\": train_config.num_epochs,\n",
    "        \"batch_size\": train_config.batch_size,\n",
    "        \"learning_rate\": train_config.learning_rate,\n",
    "        \"model\": train_config.model_name,\n",
    "        \"optimizer\": train_config.optimizer,\n",
    "        \"scheduler\": train_config.scheduler if train_config.use_scheduler else \"none\",\n",
    "        \"dataset_mean\": data_module.mean,\n",
    "        \"dataset_std\": data_module.std,\n",
    "        \"num_classes\": data_module.num_classes,\n",
    "        \"checkpoint_path\": str(best_checkpoint.name)\n",
    "    }\n",
    "\n",
    "    with open(dataset_dir / \"training_summary.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"âœ“ Saved training summary\")\n",
    "\n",
    "    # Copy ALL TensorBoard logs (full logs for offline review)\n",
    "    tb_logs_src = Path(system_config.output_dir) / \"kenyan_food_logs\"\n",
    "    if tb_logs_src.exists():\n",
    "        tb_logs_dest = dataset_dir / \"tensorboard_logs\"\n",
    "\n",
    "        print(f\"Copying TensorBoard logs from {tb_logs_src}...\")\n",
    "        shutil.copytree(tb_logs_src, tb_logs_dest, dirs_exist_ok=True)\n",
    "\n",
    "        # Count total size of logs for user info\n",
    "        total_size_bytes = sum(f.stat().st_size for f in tb_logs_dest.rglob('*') if f.is_file())\n",
    "        total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "        print(f\"âœ“ Saved TensorBoard logs ({total_size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"[WARN] TensorBoard logs not found at {tb_logs_src}\")\n",
    "\n",
    "    # Create a ZIP file for easy download\n",
    "    print(\"\\nCreating ZIP archive for download...\")\n",
    "    zip_path = Path(\"/kaggle/working/kenyan_food_model_output\")\n",
    "    shutil.make_archive(str(zip_path), 'zip', dataset_dir)\n",
    "    zip_size_mb = Path(f\"{zip_path}.zip\").stat().st_size / (1024 * 1024)\n",
    "    print(f\"âœ“ Created kenyan_food_model_output.zip ({zip_size_mb:.1f} MB)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[OK] OUTPUT READY FOR DOWNLOAD!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nFiles saved to: /kaggle/working/kenyan_food_model_output/\")\n",
    "    print(\"ZIP file: /kaggle/working/kenyan_food_model_output.zip\")\n",
    "    print(\"\\nContents:\")\n",
    "    print(\"  - best_model.ckpt           : Best model checkpoint\")\n",
    "    print(\"  - training_summary.json     : Training metrics and config\")\n",
    "    print(\"  - tensorboard_logs/         : Full TensorBoard event files\")\n",
    "    print(\"\\nTo download:\")\n",
    "    print(\"1. Click 'Output' tab in the right sidebar\")\n",
    "    print(\"2. Find 'kenyan_food_model_output.zip'\")\n",
    "    print(\"3. Click the download button\")\n",
    "    print(\"\\nOr use Kaggle API to create a dataset for reuse in other notebooks!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284f858",
   "metadata": {},
   "source": [
    "## Step 8: Generate Test Predictions\n",
    "\n",
    "After training completes, generate predictions on test data and create submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ad371e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained EfficientNetV2-S weights...\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 20,233,520 / 21,458,488 parameters (94.3%)\n",
      "[INFO] Using device: cuda\n",
      "[INFO] Loading model from checkpoint: /kaggle/working/output/checkpoints/32-0.8257.ckpt\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 20,233,520 / 21,458,488 parameters (94.3%)\n",
      "[INFO] Using device: cuda\n",
      "[INFO] Loading model from checkpoint: /kaggle/working/output/checkpoints/32-0.8257.ckpt\n",
      "Loading pre-trained EfficientNetV2-S weights...\n",
      "Loading pre-trained EfficientNetV2-S weights...\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 20,233,520 / 21,458,488 parameters (94.3%)\n",
      "[OK] Model loaded successfully\n",
      "[INFO] Using preprocessing for efficientnetv2: size=384, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
      "[INFO] Loading test dataset from /kaggle/input/opencv-pytorch-project-2-classification-round-3/test.csv\n",
      "[INFO] Test mode: Loading 1638 test samples (no labels)\n",
      "[INFO] CSV columns: ['id']\n",
      "[INFO] Test dataset size: 1638\n",
      "[INFO] Starting inference...\n",
      "[OK] Pre-trained EfficientNetV2-S weights loaded successfully\n",
      "Freezing early layers, unfreezing later layers for fine-tuning...\n",
      "  Layers frozen: 0 / 3\n",
      "  Trainable: 20,233,520 / 21,458,488 parameters (94.3%)\n",
      "[OK] Model loaded successfully\n",
      "[INFO] Using preprocessing for efficientnetv2: size=384, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
      "[INFO] Loading test dataset from /kaggle/input/opencv-pytorch-project-2-classification-round-3/test.csv\n",
      "[INFO] Test mode: Loading 1638 test samples (no labels)\n",
      "[INFO] CSV columns: ['id']\n",
      "[INFO] Test dataset size: 1638\n",
      "[INFO] Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:48<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Generated 1638 predictions\n",
      "[INFO] Loading class mapping from training data...\n",
      "[INFO] Using column 'class' as label column\n",
      "[INFO] CSV columns: ['id', 'class']\n",
      "Using 5228 samples for training.\n",
      "Class to index mapping: {'bhaji': 0, 'chapati': 1, 'githeri': 2, 'kachumbari': 3, 'kukuchoma': 4, 'mandazi': 5, 'masalachips': 6, 'matoke': 7, 'mukimo': 8, 'nyamachoma': 9, 'pilau': 10, 'sukumawiki': 11, 'ugali': 12}\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "[OK] Loaded class mapping with 13 classes\n",
      "[OK] Submission saved to: /kaggle/working/submission.csv\n",
      "[INFO] Submission shape: (1638, 2)\n",
      "[INFO] Sample predictions:\n",
      "               image_id        label\n",
      "0   9156739011499789258   nyamachoma\n",
      "1   2049465964503133373   kachumbari\n",
      "2   6446998501027132988   nyamachoma\n",
      "3   4194396063119815321        ugali\n",
      "4   9018117998187006009   kachumbari\n",
      "5   6246759883907852128  masalachips\n",
      "6  16478122708528316044   nyamachoma\n",
      "7  14045745760440690312        pilau\n",
      "8   7872954221890963019       matoke\n",
      "9   4868486697531317477      chapati\n",
      "\n",
      "[INFO] Prediction distribution:\n",
      "label\n",
      "chapati        233\n",
      "nyamachoma     207\n",
      "ugali          166\n",
      "bhaji          158\n",
      "mandazi        157\n",
      "githeri        123\n",
      "kachumbari     115\n",
      "masalachips    111\n",
      "sukumawiki     109\n",
      "matoke         107\n",
      "Name: count, dtype: int64\n",
      "[OK] Submission created: /kaggle/working/submission.csv\n",
      "[INFO] Total predictions: 1638\n",
      "\n",
      "[INFO] Prediction distribution:\n",
      "label\n",
      "chapati        233\n",
      "nyamachoma     207\n",
      "ugali          166\n",
      "bhaji          158\n",
      "mandazi        157\n",
      "githeri        123\n",
      "kachumbari     115\n",
      "masalachips    111\n",
      "sukumawiki     109\n",
      "matoke         107\n",
      "pilau           73\n",
      "mukimo          53\n",
      "kukuchoma       26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[OK] Ready to download and submit to Kaggle!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.inference import create_submission\n",
    "if g_inference_only:\n",
    "    checkpoint_path = \"/kaggle/working/kenyan_food_model_output/best_model.ckpt\"\n",
    "else:\n",
    "    checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "# Generate predictions and create submission.csv\n",
    "# Automatically detects Kaggle environment and uses correct paths\n",
    "submission_df = create_submission(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    output_csv_path=\"/kaggle/working/submission.csv\",\n",
    "    model_config=train_config,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "print(f\"[OK] Submission created: /kaggle/working/submission.csv\")\n",
    "print(f\"[INFO] Total predictions: {len(submission_df)}\")\n",
    "print(f\"\\n[INFO] Prediction distribution:\")\n",
    "print(submission_df['label'].value_counts())\n",
    "print(\"\\n[OK] Ready to download and submit to Kaggle!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef3826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
