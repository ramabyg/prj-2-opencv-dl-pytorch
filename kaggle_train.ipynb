{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ce9fd3",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository (Kaggle Only)\n",
    "\n",
    "Run this cell on Kaggle to get the latest code from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cbce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'prj-2-opencv-dl-pytorch'...\n",
      "remote: Enumerating objects: 79, done.\u001b[K\n",
      "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
      "remote: Enumerating objects: 79, done.\u001b[K[K\n",
      "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
      "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
      "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
      "remote: Total 79 (delta 36), reused 62 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (79/79), 1.37 MiB | 11.13 MiB/s, done.\n",
      "Resolving deltas: 100% (36/36), done.\n",
      "remote: Total 79 (delta 36), reused 62 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (79/79), 1.37 MiB | 11.13 MiB/s, done.\n",
      "Resolving deltas: 100% (36/36), done.\n",
      "✓ Repository cloned and added to path\n",
      "✓ Repository cloned and added to path\n"
     ]
    }
   ],
   "source": [
    "#delete directory if exists\n",
    "import shutil\n",
    "import os\n",
    "if os.path.exists('prj-2-opencv-dl-pytorch'):\n",
    "    shutil.rmtree('prj-2-opencv-dl-pytorch')\n",
    "# Clone repository from GitHub\n",
    "!git clone https://github.com/ramabyg/prj-2-opencv-dl-pytorch.git\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/prj-2-opencv-dl-pytorch')\n",
    "\n",
    "print(\"✓ Repository cloned and added to path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f0eea",
   "metadata": {},
   "source": [
    "## Step 2: Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3432eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "from src.config import get_config\n",
    "from src.datamodule import KenyanFood13DataModule\n",
    "from src.model import KenyanFood13Classifier\n",
    "from src.trainer import train_model\n",
    "from src.utils import calculate_dataset_mean_std\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412f178",
   "metadata": {},
   "source": [
    "## Step 3: Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8216c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epochs\n",
      "Batch size: 32\n",
      "Device: cuda\n",
      "Output directory: /kaggle/working/output\n"
     ]
    }
   ],
   "source": [
    "# Get configurations (auto-detects Kaggle environment)\n",
    "train_config, data_config, system_config = get_config(\n",
    "    num_epochs=100,          # Adjust as needed\n",
    "    batch_size=32,           # Larger batch for multi-GPU\n",
    "    learning_rate=0.001,\n",
    "    use_scheduler=True,\n",
    "    scheduler=\"cosine\"\n",
    ")\n",
    "\n",
    "print(f\"Training for {train_config.num_epochs} epochs\")\n",
    "print(f\"Batch size: {train_config.batch_size}\")\n",
    "print(f\"Device: {system_config.device}\")\n",
    "print(f\"Output directory: {system_config.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa728d",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Dataset Statistics (Optional)\n",
    "\n",
    "You can skip this and use ImageNet defaults for faster startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b900ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mean and std from all 6536 images...\n",
      "  Processed 6500/6536 images...\n",
      "✓ Successfully processed 6536 images (0 errors)\n",
      "  Calculated mean: [0.5672, 0.4663, 0.3659]\n",
      "  Calculated std:  [0.2484, 0.2561, 0.2600]\n",
      "\n",
      "✓ Successfully processed 6536 images (0 errors)\n",
      "  Calculated mean: [0.5672, 0.4663, 0.3659]\n",
      "  Calculated std:  [0.2484, 0.2561, 0.2600]\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Calculate from dataset (more accurate)\n",
    "# mean, std = calculate_dataset_mean_std(\n",
    "#     annotations_file=data_config.annotations_file,\n",
    "#     img_dir=data_config.img_dir,\n",
    "#     sample_size=None  # Use more samples on Kaggle, None means use all images\n",
    "# )\n",
    "\n",
    "# Option 2: Use ImageNet defaults (faster)\n",
    "# from src.utils import get_imagenet_stats\n",
    "# mean, std = get_imagenet_stats()\n",
    "\n",
    "#Option 3: Use pre computed values (fastest)\n",
    "mean = [0.5672, 0.4663, 0.3659]\n",
    "std = [0.2484, 0.2561, 0.2600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e65433",
   "metadata": {},
   "source": [
    "## Step 5: Create Data Module and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdaade51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5228 samples for training.\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "Using 1308 samples for validation.\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "✓ Data module created with 13 classes\n",
      "Loading pre-trained GoogleNet weights...\n",
      "✓ Pre-trained weights loaded successfully\n",
      "✓ Model created: googlenet\n",
      "✓ Pre-trained weights loaded successfully\n",
      "✓ Model created: googlenet\n"
     ]
    }
   ],
   "source": [
    "# Create data module\n",
    "data_module = KenyanFood13DataModule(data_config, mean=mean, std=std)\n",
    "data_module.setup()\n",
    "\n",
    "print(f\"✓ Data module created with {data_module.num_classes} classes\")\n",
    "\n",
    "# Create model\n",
    "model = KenyanFood13Classifier(train_config, data_module.num_classes)\n",
    "\n",
    "print(f\"✓ Model created: {train_config.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9958a4",
   "metadata": {},
   "source": [
    "## Step 6: Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cc9310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting Training\n",
      "============================================================\n",
      "Using 5228 samples for training.\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "Using 1308 samples for validation.\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n",
      "Using 5228 samples for training.\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "Using 1308 samples for validation.\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/output exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9264131f9d4000ae82748fa15f62aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857a8ebc8b344759b93f23b0096c3b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9902cf95989449309d83f8becef2c6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960dd25e8d9f4cfa81fcb2ee3ba40ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running Final Validation\n",
      "============================================================\n",
      "Using 5228 samples for training.\n",
      "Dataset initialized with 5228 samples belonging to 13 classes.\n",
      "Using 1308 samples for validation.\n",
      "Dataset initialized with 1308 samples belonging to 13 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2d98e7cf6e44ddbe53f223240fb02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           step            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            2.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         valid/acc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4018373489379883     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         valid/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3618100881576538     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        valid/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.7326213121414185     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      valid/precision      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4728693962097168     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       valid/recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4018373489379883     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          step           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           2.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        valid/acc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4018373489379883    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        valid/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3618100881576538    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       valid/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.7326213121414185    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     valid/precision     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4728693962097168    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      valid/recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4018373489379883    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best model saved to: /kaggle/working/output/1-0.4018.ckpt\n",
      "Best validation accuracy: 0.4018\n",
      "============================================================\n",
      "\n",
      "\n",
      "✓ Training complete!\n",
      "Best model: /kaggle/working/output/1-0.4018.ckpt\n",
      "Best accuracy: 0.4018\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model, _, checkpoint_callback = train_model(\n",
    "    training_config=train_config,\n",
    "    data_config=data_config,\n",
    "    system_config=system_config,\n",
    "    model=model,\n",
    "    data_module=data_module\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training complete!\")\n",
    "print(f\"Best model: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"Best accuracy: {checkpoint_callback.best_model_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f4f58",
   "metadata": {},
   "source": [
    "## Step 7: Save Outputs to Kaggle Dataset\n",
    "\n",
    "This will save your trained model and training summary to a Kaggle Dataset for easy access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187739b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best checkpoint: 1-0.4018.ckpt\n",
      "✓ Saved training summary\n",
      "Copying TensorBoard logs from /kaggle/working/output/kenyan_food_logs...\n",
      "✓ Saved TensorBoard logs (0.0 MB)\n",
      "\n",
      "============================================================\n",
      "Output saved to: /kaggle/working/kenyan_food_model_output\n",
      "============================================================\n",
      "\n",
      "What's saved:\n",
      "  - best_model.ckpt (trained model)\n",
      "  - training_summary.json (metrics & config)\n",
      "  - tensorboard_logs/ (full logs for offline review)\n",
      "\n",
      "Next steps:\n",
      "1. Click 'Save Version' in Kaggle (top right)\n",
      "2. After run completes, go to 'Output' tab\n",
      "3. Click 'New Dataset' and name it (e.g., 'kenyan-food-model-v1')\n",
      "4. Download anytime or use in other notebooks!\n",
      "\n",
      "To view TensorBoard logs locally:\n",
      "  1. Download the dataset\n",
      "  2. Extract it\n",
      "  3. Run: tensorboard --logdir=tensorboard_logs\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a clean output directory for the dataset\n",
    "dataset_dir = Path(\"/kaggle/working/kenyan_food_model_output\")\n",
    "if dataset_dir.exists():\n",
    "    shutil.rmtree(dataset_dir)\n",
    "dataset_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy the best checkpoint\n",
    "best_checkpoint = Path(checkpoint_callback.best_model_path)\n",
    "if best_checkpoint.exists():\n",
    "    shutil.copy(best_checkpoint, dataset_dir / \"best_model.ckpt\")\n",
    "    print(f\"✓ Saved best checkpoint: {best_checkpoint.name}\")\n",
    "\n",
    "# Save training summary as JSON\n",
    "summary = {\n",
    "    \"best_val_accuracy\": float(checkpoint_callback.best_model_score),\n",
    "    \"num_epochs\": train_config.num_epochs,\n",
    "    \"batch_size\": train_config.batch_size,\n",
    "    \"learning_rate\": train_config.learning_rate,\n",
    "    \"model\": train_config.model_name,\n",
    "    \"optimizer\": train_config.optimizer,\n",
    "    \"scheduler\": train_config.scheduler if train_config.use_scheduler else \"none\",\n",
    "    \"dataset_mean\": mean,\n",
    "    \"dataset_std\": std,\n",
    "    \"num_classes\": data_module.num_classes,\n",
    "    \"checkpoint_path\": str(best_checkpoint.name)\n",
    "}\n",
    "\n",
    "with open(dataset_dir / \"training_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"✓ Saved training summary\")\n",
    "\n",
    "# Copy ALL TensorBoard logs (full logs for offline review)\n",
    "tb_logs_src = Path(system_config.output_dir) / \"kenyan_food_logs\"\n",
    "if tb_logs_src.exists():\n",
    "    tb_logs_dest = dataset_dir / \"tensorboard_logs\"\n",
    "\n",
    "    print(f\"Copying TensorBoard logs from {tb_logs_src}...\")\n",
    "    shutil.copytree(tb_logs_src, tb_logs_dest, dirs_exist_ok=True)\n",
    "\n",
    "    # Calculate total size\n",
    "    total_size = sum(f.stat().st_size for f in tb_logs_dest.rglob('*') if f.is_file())\n",
    "    print(f\"✓ Saved TensorBoard logs ({total_size / 1_000_000:.1f} MB)\")\n",
    "else:\n",
    "    print(\"⚠ No TensorBoard logs found\")\n",
    "\n",
    "# Create a ZIP file for easy download\n",
    "print(\"\\nCreating ZIP file...\")\n",
    "zip_path = Path(\"/kaggle/working/kenyan_food_model_output.zip\")\n",
    "if zip_path.exists():\n",
    "    zip_path.unlink()\n",
    "\n",
    "shutil.make_archive(\n",
    "    str(zip_path.with_suffix('')),  # Remove .zip, make_archive adds it\n",
    "    'zip',\n",
    "    dataset_dir\n",
    ")\n",
    "\n",
    "zip_size = zip_path.stat().st_size / 1_000_000\n",
    "print(f\"✓ Created ZIP file: {zip_path.name} ({zip_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Output saved to: {dataset_dir}\")\n",
    "print(f\"ZIP file: {zip_path}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nWhat's saved:\")\n",
    "print(f\"  - best_model.ckpt (trained model)\")\n",
    "print(f\"  - training_summary.json (metrics & config)\")\n",
    "print(f\"  - tensorboard_logs/ (full logs for offline review)\")\n",
    "print(\"\\nDownload options:\")\n",
    "print(\"  Option 1: Download ZIP directly from Output tab\")\n",
    "print(\"    → Look for 'kenyan_food_model_output.zip'\")\n",
    "print(\"    → Click to download (single file, faster)\")\n",
    "print(\"\\n  Option 2: Create as Kaggle Dataset\")\n",
    "print(\"    1. Click 'Save Version' in Kaggle (top right)\")\n",
    "print(\"    2. After run completes, go to 'Output' tab\")\n",
    "print(\"    3. Click 'New Dataset' and name it (e.g., 'kenyan-food-model-v1')\")\n",
    "print(\"    4. Reusable in other notebooks!\")\n",
    "print(\"\\nTo view TensorBoard logs locally:\")\n",
    "print(\"  1. Extract the ZIP file\")\n",
    "print(\"  2. Run: tensorboard --logdir=kenyan_food_model_output/tensorboard_logs\")\n",
    "print(\"  3. Open: http://localhost:6006\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7284f858",
   "metadata": {},
   "source": [
    "## Step 8: Generate Predictions (TODO)\n",
    "\n",
    "Add your inference code here to generate submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ad371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load test data and generate predictions\n",
    "# TODO: Create submission.csv\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
